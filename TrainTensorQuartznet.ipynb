{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","toc_visible":true,"authorship_tag":"ABX9TyMDFpA0kID/Ff414VDkDNJP"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["TODO: Evaluate how depthwise convolution not being tensorised affect the overall project"],"metadata":{"id":"muvUbKN_83ln"}},{"cell_type":"code","execution_count":1,"metadata":{"id":"rIOyKnYZxMh7","executionInfo":{"status":"ok","timestamp":1693508296715,"user_tz":-120,"elapsed":30187,"user":{"displayName":"Rodrigo Hernández","userId":"13809504810916014110"}}},"outputs":[],"source":["# ------------------------------------------------------------------------------\n","#                             WARNING\n","# For any nep50 numpy related error, restart the kernel and re-run the imports cell.\n","#             It works out as packages need to be replaced.\n","# Source: https://github.com/nanoporetech/bonito/blob/v0.4.0/notebooks/bonito-train.ipynb\n","# ------------------------------------------------------------------------------\n","\n","# Install some packages\n","!pip install -q ont-bonito\n","!pip install -q fast-ctc-decode\n","!pip install -q tensorly\n","!pip install -q tensorly-torch\n","\n","# Some python built-in packages\n","import os\n","import sys\n","import time\n","import random\n","from datetime import datetime\n","from itertools import starmap\n","from time import perf_counter\n","from functools import partial\n","import numpy as np\n","import pandas as pd\n","import toml\n","from tqdm import tqdm\n","\n","# Pytorch imports\n","import torch\n","import torch.nn as nn\n","from torch.nn.functional import ctc_loss, log_softmax\n","from torch.nn import Module, ModuleList, Sequential, Conv1d, BatchNorm1d, Dropout, LSTM, GRU, ReLU, SiLU\n","from torch.optim import AdamW\n","from torch.utils.data import DataLoader\n","from torch.optim.lr_scheduler import CosineAnnealingLR\n","\n","# Google suite imports for data handling\n","from google.colab import auth\n","from google.colab import drive as gdrive\n","from oauth2client.client import GoogleCredentials\n","from pydrive.auth import GoogleAuth\n","from pydrive.drive import GoogleDrive\n","\n","# ONT packages\n","from bonito.ctc.model import Model\n","from bonito.util import accuracy, decode_ref, permute, concat\n","from bonito.data import ChunkDataSet\n","from bonito.nn import Permute\n","\n","from fast_ctc_decode import beam_search, viterbi_search\n","\n","# Tensor decomposition packages\n","import tensorly\n","from tltorch import FactorizedConv"]},{"cell_type":"markdown","source":["---\n","\n","#GOOGLE CREDENTIALS"],"metadata":{"id":"9tEZqHMnJgW8"}},{"cell_type":"code","source":["# Authenticate and create PyDrive client.\n","auth.authenticate_user()\n","gauth = GoogleAuth()\n","gauth.credentials = GoogleCredentials.get_application_default()\n","drive = GoogleDrive(gauth)\n","\n","# helper functions for importing data\n","def download_npy_from_link(fn, link):\n","    _, id = link.split('=')\n","    downloaded = drive.CreateFile({'id':id})\n","    downloaded.GetContentFile(fn)\n","    return np.load(fn)\n","\n","def download_toml_from_link(fn, link):\n","    _, id = link.split('=')\n","    downloaded = drive.CreateFile({'id':id})\n","    downloaded.GetContentFile(fn)\n","    return toml.load(fn)"],"metadata":{"id":"KUDZ8oJv9eAi","executionInfo":{"status":"ok","timestamp":1693508335679,"user_tz":-120,"elapsed":9493,"user":{"displayName":"Rodrigo Hernández","userId":"13809504810916014110"}}},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":["---\n","# DOWNLOAD SAMPLE DATASET"],"metadata":{"id":"2s6X35tKJsHH"}},{"cell_type":"code","source":["chunks_link = \"https://drive.google.com/open?id=1aciNfQs53eFRwnMggInY-Uisi-owtmzY\" #@param {type:\"string\"}\n","references_link = \"https://drive.google.com/open?id=1kcs_hZMndUIDX2n8dTxGrAgCvt_TpUcH\" #@param {type:\"string\"}\n","reference_lengths_link = \"https://drive.google.com/open?id=1-r7XymddP_3gKFb-7ohB_t14u7u4SGLm\" #@param {type:\"string\"}\n","quartznet_config_link = \"https://drive.google.com/open?id=1mLqxHMYKA4vfK9wd_2YgaBGzWPVBeilI\" #@param {t"],"metadata":{"id":"KA8gyuU--0IN","executionInfo":{"status":"ok","timestamp":1693508340936,"user_tz":-120,"elapsed":236,"user":{"displayName":"Rodrigo Hernández","userId":"13809504810916014110"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["print('Loading chunks.')\n","full_chunks = download_npy_from_link('chunks.npy',\n","                                chunks_link)\n","# Sections of squiggle that correspond with the target reference sequence\n","# Variable length and zero padded (upto 4096 samples).\n","# shape (1000000, 4096)\n","# dtype('float32')\n","\n","print('Loading references.')\n","full_targets = download_npy_from_link('references.npy',\n","                                 references_link)\n","# Integer encoded target sequence {'A': 1, 'C': 2, 'G': 3, 'T': 4}\n","# Variable length and zero padded (default range between 128 and 256).\n","# shape (1000000, 256)\n","# dtype('uint8')\n","\n","print('Loading reference lengths.')\n","full_target_lengths = download_npy_from_link('reference_lengths.npy',\n","                                        reference_lengths_link)\n","# Lengths of target sequences in references.npy\n","# shape (1000000,)\n","# dtype('uint8')\n","\n","print('Loading quartznet config.')\n","quartznet_config = download_toml_from_link(\"config_quartznet5x5.toml\",\n","                                           quartznet_config_link)\n","# The structure of the model is defined using a config file.\n","# This will make sense to those familar with QuartzNet\n","\n","\n","# https://arxiv.org/pdf/1910.10261.pdf)."],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6znKdewm_lc2","executionInfo":{"status":"ok","timestamp":1693508457161,"user_tz":-120,"elapsed":114877,"user":{"displayName":"Rodrigo Hernández","userId":"13809504810916014110"}},"outputId":"4a44de1d-b6ae-4937-b611-9814ada9466e"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Loading chunks.\n","Loading references.\n","Loading reference lengths.\n","Loading quartznet config.\n"]}]},{"cell_type":"markdown","source":["# TENSORISED QUARTZNET MODEL"],"metadata":{"id":"Rrj93Xx1ribe"}},{"cell_type":"code","execution_count":37,"metadata":{"id":"pazGLmasvrny","executionInfo":{"status":"ok","timestamp":1693510226051,"user_tz":-120,"elapsed":213,"user":{"displayName":"Rodrigo Hernández","userId":"13809504810916014110"}}},"outputs":[],"source":["# This is the model we have tweaked\n","# Source: https://github.com/nanoporetech/bonito/blob/v0.3.0/bonito/ctc/model.py\n","# Factorization shoul dbe changed directly in the Encoder and Decoder classes\n","\n","\n","class TensorModel(Module):\n","    \"\"\"\n","    Model template for QuartzNet style architectures\n","\n","    https://arxiv.org/pdf/1910.10261.pdf\n","    \"\"\"\n","    def __init__(self, config):\n","        super(TensorModel, self).__init__()\n","        if 'qscore' not in config:\n","            self.qbias = 0.0\n","            self.qscale = 1.0\n","        else:\n","            self.qbias = config['qscore']['bias']\n","            self.qscale = config['qscore']['scale']\n","\n","        self.config = config\n","        self.stride = config['block'][0]['stride'][0]\n","        self.alphabet = config['labels']['labels']\n","        self.features = config['block'][-1]['filters']\n","        self.encoder = Encoder(config)\n","        self.decoder = Decoder(self.features, len(self.alphabet))\n","\n","    def forward(self, x):\n","        encoded = self.encoder(x)\n","        return self.decoder(encoded)\n","\n","    def decode(self, x, beamsize=5, threshold=1e-3, qscores=False, return_path=False):\n","        x = x.exp().cpu().numpy().astype(np.float32)\n","        if beamsize == 1 or qscores:\n","            seq, path  = viterbi_search(x, self.alphabet, qscores, self.qscale, self.qbias)\n","        else:\n","            seq, path = beam_search(x, self.alphabet, beamsize, threshold)\n","        if return_path: return seq, path\n","        return seq\n","\n","\n","class Encoder(Module):\n","    \"\"\"\n","    Builds the model encoder\n","    \"\"\"\n","    def __init__(self, config):\n","        super(Encoder, self).__init__()\n","        self.config = config\n","\n","        self.activations = {\"relu\": ReLU,\"swish\": SiLU}\n","        features = self.config['input']['features']\n","        activation = self.activations[self.config['encoder']['activation']]()\n","        encoder_layers = []\n","\n","        # Change factorization in the loop below (\"tucker\" | \"cp\")\n","        for layer in self.config['block']:\n","            encoder_layers.append(\n","                Block(\n","                    features, layer['filters'], activation,\n","                    repeat=layer['repeat'], kernel_size=layer['kernel'],\n","                    stride=layer['stride'], dilation=layer['dilation'],\n","                    dropout=layer['dropout'], residual=layer['residual'],\n","                    separable=layer['separable'], factorization=\"tucker\"\n","                )\n","            )\n","\n","            features = layer['filters']\n","\n","        self.encoder = Sequential(*encoder_layers)\n","\n","    def forward(self, x):\n","        return self.encoder(x)\n","\n","\n","class TCSConv1d(Module):\n","    \"\"\"\n","    Time-Channel Separable 1D Convolution. This needs to be tensorised\n","    \"\"\"\n","    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, factorization=\"tucker\", bias=False, separable=False):\n","\n","        super(TCSConv1d, self).__init__()\n","        self.separable = separable\n","\n","        # TODO - insert factorization: 'cp', 'tucker', as a parameter in the attributes of the class\n","        \"\"\"\n","        FactorizedConv parameters:\n","        in_channels, out_channels, kernel_size, order=None,\n","        stride=1, padding=0, dilation=1, bias=False, has_bias=False, n_layers=1,\n","        factorization='cp', rank='same', implementation='factorized', fixed_rank_modes=None,\n","        device=None, dtype=None)\"\"\"\n","\n","        if separable:\n","            # This layer cannot be factorised until \"groups is implemented in tensorly-torch\".\n","            self.depthwise = Conv1d(\n","                in_channels, in_channels, kernel_size=kernel_size, stride=stride,\n","                padding=padding, dilation=dilation, bias=bias, groups=in_channels\n","            )\n","            self.pointwise = FactorizedConv(\n","                in_channels= in_channels, out_channels = out_channels, kernel_size=1, stride=1,\n","                dilation=dilation, bias=bias, padding=0, factorization=factorization,\n","                rank=\"same\", order=1\n","            )\n","        # Separable false by default\n","        else:\n","            self.conv = FactorizedConv(\n","                in_channels= in_channels, out_channels = out_channels, kernel_size=kernel_size,\n","                stride=stride, padding=padding, dilation=dilation, bias=bias, factorization=factorization,\n","                rank=\"same\", order=1\n","            )\n","\n","    def forward(self, x):\n","        if self.separable:\n","            x = self.depthwise(x)\n","            x = self.pointwise(x)\n","        else:\n","            x = self.conv(x)\n","        return x\n","\n","\n","class Block(Module):\n","    \"\"\"\n","    TCSConv, Batch Normalisation, Activation, Dropout\n","    \"\"\"\n","    def __init__(self, in_channels, out_channels, activation, repeat=5, kernel_size=1, stride=1, dilation=1, dropout=0.0, residual=False, separable=False, factorization= \"tucker\"):\n","\n","        super(Block, self).__init__()\n","\n","        self.use_res = residual\n","        self.conv = ModuleList()\n","\n","        _in_channels = in_channels\n","        padding = self.get_padding(kernel_size[0], stride[0], dilation[0])\n","\n","        # add the first n - 1 convolutions + activation\n","        for _ in range(repeat - 1):\n","            self.conv.extend(\n","                self.get_tcs(\n","                    _in_channels, out_channels, kernel_size=kernel_size,\n","                    stride=stride, dilation=dilation,\n","                    padding=padding, separable=separable,\n","                    factorization=factorization\n","                )\n","            )\n","\n","            self.conv.extend(self.get_activation(activation, dropout))\n","            _in_channels = out_channels\n","\n","        # add the last conv and batch norm\n","        self.conv.extend(\n","            self.get_tcs(\n","                _in_channels, out_channels,\n","                kernel_size=kernel_size,\n","                stride=stride, dilation=dilation,\n","                padding=padding, separable=separable,\n","                factorization=factorization\n","            )\n","        )\n","\n","        # add the residual connection\n","        if self.use_res:\n","            self.residual = Sequential(*self.get_tcs(in_channels, out_channels))\n","\n","        # add the activation and dropout\n","        self.activation = Sequential(*self.get_activation(activation, dropout))\n","\n","    def get_activation(self, activation, dropout):\n","        return activation, Dropout(p=dropout)\n","\n","    def get_padding(self, kernel_size, stride, dilation):\n","        if stride > 1 and dilation > 1:\n","            raise ValueError(\"Dilation and stride can not both be greater than 1\")\n","        return (kernel_size // 2) * dilation\n","\n","    def get_tcs(self, in_channels, out_channels, kernel_size=1, stride=1, dilation=1, padding=0, bias=False, separable=False, factorization=\"tucker\"):\n","        return [\n","            TCSConv1d(\n","                in_channels, out_channels, kernel_size,\n","                stride=stride, dilation=dilation, padding=padding,\n","                bias=bias, separable=separable, factorization=factorization\n","            ),\n","            BatchNorm1d(out_channels, eps=1e-3, momentum=0.1)\n","        ]\n","\n","    def forward(self, x):\n","        _x = x\n","        for layer in self.conv:\n","            _x = layer(_x)\n","        if self.use_res:\n","            _x = _x + self.residual(x)\n","        return self.activation(_x)\n","\n","\n","class Decoder(Module):\n","    \"\"\"\n","    Decoder\n","    \"\"\"\n","    # Change factorization in the layer below (\"tucker\" | \"cp\")\n","    def __init__(self, features, classes):\n","        super(Decoder, self).__init__()\n","        self.layers = Sequential(\n","                                FactorizedConv(in_channels=features, out_channels=classes, kernel_size=1,\n","                                bias=True,factorization=\"tucker\", rank=\"same\", order=1),\n","                      Permute([2, 0, 1])\n","        )\n","\n","    def forward(self, x):\n","        return log_softmax(self.layers(x), dim=2)"]},{"cell_type":"markdown","source":["---\n","\n","# TRAINING OPTIONS\n","\n","Training options\n","Default options are set, and ranges are sensible, but most combinations of settings are untested.\n","\n","The default settings will train on a small amount of data (1000 signal chunks) for a small number of epochs (20). This is unlikely to produce an accurate generalisable model, but will train relatively quickly.\n","\n","After modifying this cell, Runtime -> Run after, so that all cells between this one and the main train looping will be run in accordance with new setting.\n","\n","A train_proportion of 0.90 will use 90% of the data for training and 10% for validation.\n","\n","No dropout is applied by default, but in order to avoid overfitting on small data sets it may be necessary to apply dropout (e.g. of 0.5), or other regularisation techniques."],"metadata":{"id":"oIpbgRnjBHgX"}},{"cell_type":"code","source":["\n","model_savepath = '/content/drive/My Drive/tenitobook/' #@param {type:\"string\"}\n","learning_rate = 0.001 #@param {type:\"number\"}\n","random_seed = 25 #@param {type:\"integer\"}\n","epochs = 20 #@param {type:\"slider\", min:1, max:1000, step:1}\n","batch_size = 8 #@param [2, 4, 8, 16, 28] {type:\"raw\"}\n","num_chunks = 10000 #@param [10, 100, 1000, 10000, 100000] {type:\"raw\"}\n","train_proportion = 0.80 #@param type:\"slider\", min:0.8, max:1000, step:1\n","\n","dropout = 0.0 #@param {type:\"slider\", min:0.0, max:0.8}"],"metadata":{"id":"pqYn5uhn_pWB","executionInfo":{"status":"ok","timestamp":1693509986605,"user_tz":-120,"elapsed":2,"user":{"displayName":"Rodrigo Hernández","userId":"13809504810916014110"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","source":["\n","# Initialise random libs and setup cudnn\n","random.seed(random_seed)\n","np.random.seed(random_seed)\n","torch.manual_seed(random_seed)\n","torch.backends.cudnn.enabled = True\n","torch.backends.cudnn.deterministic = True\n","torch.backends.cudnn.benchmark = False\n","\n","# we exploit GPU for training\n","device = torch.device(\"cuda\")"],"metadata":{"id":"W8022GSEBPmt","executionInfo":{"status":"ok","timestamp":1693509987900,"user_tz":-120,"elapsed":246,"user":{"displayName":"Rodrigo Hernández","userId":"13809504810916014110"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","source":["\n","# subset\n","chunks = full_chunks[:num_chunks]\n","targets = full_targets[:num_chunks]\n","target_lengths = full_target_lengths[:num_chunks]\n","\n","# shuffle\n","shuf = np.random.permutation(chunks.shape[0])\n","chunks = chunks[shuf]\n","targets = targets[shuf]\n","target_lengths = target_lengths[shuf]\n","\n","split = np.floor(chunks.shape[0] * train_proportion).astype(np.int32)"],"metadata":{"id":"YoGxEnWVBS1f","executionInfo":{"status":"ok","timestamp":1693509988886,"user_tz":-120,"elapsed":170,"user":{"displayName":"Rodrigo Hernández","userId":"13809504810916014110"}}},"execution_count":24,"outputs":[]},{"cell_type":"code","source":["for b in quartznet_config['block']:\n","    b['dropout'] = dropout\n","quartznet_config"],"metadata":{"id":"LfhLmYFDC3Z3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Train function obtained from v3.0 (https://github.com/nanoporetech/bonito/blob/v0.3.0/bonito/training.py)\n","\n","def ctc_label_smoothing_loss(log_probs, targets, lengths, weights):\n","    T, N, C = log_probs.shape\n","    log_probs_lengths = torch.full(size=(N, ), fill_value=T, dtype=torch.int64)\n","    loss = ctc_loss(log_probs.to(torch.float32), targets, log_probs_lengths, lengths, reduction='mean')\n","    label_smoothing_loss = -((log_probs * weights.to(log_probs.device)).mean())\n","    return {'loss': loss + label_smoothing_loss, 'ctc_loss': loss, 'label_smooth_loss': label_smoothing_loss}\n","\n","def train(model, device, train_loader, optimizer, use_amp=False, criterion=None, lr_scheduler=None, loss_log=None):\n","\n","    if criterion is None:\n","        C = len(model.alphabet)\n","        weights = torch.cat([torch.tensor([0.4]), (0.1 / (C - 1)) * torch.ones(C - 1)]).to(device)\n","        criterion = partial(ctc_label_smoothing_loss, weights=weights)\n","\n","    chunks = 0\n","    model.train()\n","    t0 = perf_counter()\n","\n","    progress_bar = tqdm(\n","        total=len(train_loader), desc='[0/{}]'.format(len(train_loader.dataset)),\n","        ascii=True, leave=True, ncols=100, bar_format='{l_bar}{bar}| [{elapsed}{postfix}]'\n","    )\n","    smoothed_loss = {}\n","\n","    with progress_bar:\n","\n","        for data, targets, lengths in train_loader:\n","\n","            optimizer.zero_grad()\n","\n","            chunks += data.shape[0]\n","            log_probs = model(data.to(device))\n","            losses = criterion(log_probs, targets.to(device), lengths.to(device))\n","\n","            if not isinstance(losses, dict):\n","                losses = {'loss': losses}\n","\n","            if use_amp:\n","                pass\n","            else:\n","                losses['loss'].backward()\n","\n","            optimizer.step()\n","\n","            if lr_scheduler is not None: lr_scheduler.step()\n","\n","            if not smoothed_loss:\n","                smoothed_loss = {k: v.item() for k,v in losses.items()}\n","            smoothed_loss = {k: 0.01 * v.item() + 0.99 * smoothed_loss[k] for k,v in losses.items()}\n","\n","            progress_bar.set_postfix(loss='%.4f' % smoothed_loss['loss'])\n","            progress_bar.set_description(\"[{}/{}]\".format(chunks, len(train_loader.dataset)))\n","            progress_bar.update()\n","\n","            if loss_log is not None:\n","                loss_log.append({'chunks': chunks, 'time': perf_counter() - t0, **smoothed_loss})\n","\n","    return smoothed_loss['loss'], perf_counter() - t0\n","\n","def test(model, device, test_loader, min_coverage=0.5, criterion=None):\n","\n","    if criterion is None:\n","        C = len(model.alphabet)\n","        weights = torch.cat([torch.tensor([0.4]), (0.1 / (C - 1)) * torch.ones(C - 1)]).to(device)\n","        criterion = partial(ctc_label_smoothing_loss, weights=weights)\n","\n","    seqs = []\n","    model.eval()\n","    test_loss = 0\n","    accuracy_with_cov = lambda ref, seq: accuracy(ref, seq, min_coverage=min_coverage)\n","\n","    with torch.no_grad():\n","        for batch_idx, (data, target, lengths) in enumerate(test_loader, start=1):\n","            log_probs = model(data.to(device))\n","            loss = criterion(log_probs, target.to(device), lengths.to(device))\n","            test_loss += loss['ctc_loss'] if isinstance(loss, dict) else loss\n","            seqs.extend([model.decode(p) for p in permute(log_probs, 'TNC', 'NTC')])\n","\n","    refs = [\n","        decode_ref(target, model.alphabet) for target in test_loader.dataset.targets\n","    ]\n","    accuracies = [\n","        accuracy_with_cov(ref, seq) if len(seq) else 0. for ref, seq in zip(refs, seqs)\n","    ]\n","\n","    mean = np.mean(accuracies)\n","    median = np.median(accuracies)\n","    return test_loss.item() / batch_idx, mean, median"],"metadata":{"id":"AHgwaR7gwpy5","executionInfo":{"status":"ok","timestamp":1693510109309,"user_tz":-120,"elapsed":213,"user":{"displayName":"Rodrigo Hernández","userId":"13809504810916014110"}}},"execution_count":32,"outputs":[]},{"cell_type":"code","source":["#@title Set experiment name\n","experiment_name = 'tensorbonito_training_9' #@param {type:\"string\"}\n","\n","# mount users drive to save data\n","gdrive.mount('/content/drive', force_remount=True)\n","\n","# prevent overwriting of data\n","workdir = os.path.join(model_savepath, experiment_name)\n","if os.path.isdir(workdir):\n","    raise IOError('{} already exists. Select an alternative model_savepath.'.format(workdir))\n","os.makedirs(workdir)\n","\n","# data generators\n","train_dataset = ChunkDataSet(chunks[:split], targets[:split], target_lengths[:split])\n","test_dataset = ChunkDataSet(chunks[split:], targets[split:], target_lengths[split:])\n","\n","\n","# data loaders\n","train_loader = DataLoader(train_dataset, batch_size=batch_size,\n","                          shuffle=True, num_workers=2, pin_memory=True)\n","test_loader = DataLoader(test_dataset, batch_size=batch_size,\n","                         num_workers=2, pin_memory=True)\n","\n","# load bonito model\n","model = TensorModel(quartznet_config)\n","model.to(device)\n","model.train()\n","\n","# 'Connectionist Temporal Classification' (CTC) loss fuction\n","# https://distill.pub/2017/ctc/\n","criterion = nn.CTCLoss(reduction='mean')\n","\n","# set optimizer and learning rate scheduler\n","optimizer = AdamW(model.parameters(), amsgrad=True, lr=learning_rate)\n","schedular = CosineAnnealingLR(optimizer, epochs * len(train_loader))\n","\n","# report loss every\n","interval = 500 / num_chunks\n","log_interval = np.floor(len(train_dataset) / batch_size * interval)\n","\n","exp_config = os.path.join(workdir, \"experimental.log\")\n","with open(exp_config, 'a') as c:\n","    c.write('Num training chunks: {}'.format(num_chunks) + '\\n')\n","    c.write('learning rate: {}'.format(learning_rate) + '\\n')\n","    c.write('random seed: {}'.format(random_seed) + '\\n')\n","    c.write('epochs: {}'.format(epochs) + '\\n')\n","    c.write('batch_size: {}'.format(batch_size) + '\\n')\n","    c.write('train proportion: {}'.format(train_proportion) + '\\n')\n","    c.write('dropout: {}'.format(dropout) + '\\n')\n","\n","# DataFrame to store training logging information\n","training_results = pd.DataFrame()\n","\n","for epoch in range(1, epochs + 1):\n","    # v3.0\n","    train_loss, duration = train(model, device, train_loader, optimizer)\n","\n","    test_loss, mean, median = test(model, device, test_loader)\n","\n","    # collate training and validation metrics\n","    epoch_result = pd.DataFrame(\n","        {'time':[datetime.today()],\n","         'duration':[int(duration)],\n","         'epoch':[epoch],\n","         'train_loss':[train_loss],\n","         'validation_loss':[test_loss],\n","         'validation_mean':[mean],\n","         'validation_median':[median]})\n","\n","    # save model weights\n","    weights_path = os.path.join(workdir, \"weights_%s.tar\" % epoch)\n","    torch.save(model.state_dict(), weights_path)\n","\n","    # update log file\n","    log_path = os.path.join(workdir, \"training.log\")\n","    epoch_result.to_csv(log_path, mode='a', sep='\\t', index=False)\n","\n","    display(epoch_result)\n","    training_results = training_results.append(epoch_result)\n","\n","    schedular.step()\n","\n","display(training_results)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":499},"id":"DOJIhB-2HO2c","outputId":"f0c2a32b-0391-49b1-da5d-a148964575ba","executionInfo":{"status":"error","timestamp":1693510246094,"user_tz":-120,"elapsed":12426,"user":{"displayName":"Rodrigo Hernández","userId":"13809504810916014110"}}},"execution_count":38,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/tensorly/tucker_tensor.py:425: RuntimeWarning: Given only one int for 'rank' for decomposition a tensor of order 3. Using this rank for all modes.\n","  warnings.warn(message, RuntimeWarning)\n"]},{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]},{"output_type":"stream","name":"stderr","text":["[160/8000]:   2%|#2                                                              | [00:08, loss=nan]\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-38-1c3d00d14853>\u001b[0m in \u001b[0;36m<cell line: 54>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;31m# v3.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mduration\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mtest_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmedian\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-32-6eb9caa5ef39>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, device, train_loader, optimizer, use_amp, criterion, lr_scheduler, loss_log)\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msmoothed_loss\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0msmoothed_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m             \u001b[0msmoothed_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0.01\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m0.99\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0msmoothed_loss\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mprogress_bar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_postfix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'%.4f'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0msmoothed_loss\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-32-6eb9caa5ef39>\u001b[0m in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msmoothed_loss\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0msmoothed_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m             \u001b[0msmoothed_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0.01\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m0.99\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0msmoothed_loss\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mprogress_bar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_postfix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'%.4f'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0msmoothed_loss\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["CREO QUE NO CONVERGE PORQUE NO PUEDE CONVERGER. ES DECIR, HAY QUE ENTRENAR LA RED, Y LUEGO COMPRIMIRLA.\n","Y EN TODO CASO, HACER FINE TUNING. APARENTEMENTE 1 EPOCH ES MÁS QUE DE SOBRA PARA AUMENTAR LA CERTEZA.\n","ENTONCES, USAR EL MÉTODO .FROM_CONVOLUTION:\n","from_conv(conv_layer, rank='same', implementation='reconstructed', factorization='CP', decompose_weights=True, decomposition_kwargs={}, fixed_rank_modes=None, **kwargs)\n","tal y como describe, aquí: https://tensorly.org/torch/dev/modules/generated/tltorch.factorized_layers.FactorizedConv.html#tltorch.factorized_layers.FactorizedConv\n","\n","Y usar esto que pone el colega en uno de los notebooks (https://github.com/JeanKossaifi/tensorly-notebooks/blob/master/05_pytorch_backend/cnn_acceleration_tensorly_and_pytorch.ipynb):\n","\n","def count_params(network):\n","    return np.sum(np.prod(p.size()) for p in network.parameters())\n","\n","# Apply the transformation to all the Convolutional layers\n","for index, module in enumerate(model.features._modules):\n","    if index > 0:\n","        layer = model.features._modules[module]\n","        if type(layer) is torch.nn.Conv2d:\n","            ranks = [layer.weight.size(0)//2, layer.weight.size(1)//2]\n","            model.features._modules[module] = tucker_decomposition_conv_layer(layer, ranks)\n","\n","# Load another net without modification for comparison\n","original_model = models.vgg19(pretrained=True).eval()\n","\n","params_before = count_params(original_model.features)\n","params_after = count_params(model.features)\n","\n","print('Number of parameters before the decomposition: {params_before}'.format(params_before=params_before))\n","print('Number of parameters after the decomposition: {params_after}'.format(params_after=params_after))\n","print('Ratio: {ratio}'.format(ratio=float(params_after)/params_before))\n","\n","\n","\n","Es decir, hacer el conteo de parámetros de la quartznet con respecto a la tensorizada.\n","Y si hace falta reentrenar 1 epoch.\n","\n","Centrarse en medir la precisión. Con .eval()\n"],"metadata":{"id":"cL2C49ScHSkx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"wOhNJhPwJ9jl"},"execution_count":null,"outputs":[]}]}