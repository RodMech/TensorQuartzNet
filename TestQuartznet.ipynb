{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"WCRMTi9y3y_h","outputId":"f25e89af-94dc-430e-bdca-338ce205d23b"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.7/52.7 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.9/140.9 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.4/34.4 MB\u001b[0m \u001b[31m55.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m87.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.0/20.0 MB\u001b[0m \u001b[31m81.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.6/15.6 MB\u001b[0m \u001b[31m60.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.7/3.7 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.8/95.8 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m91.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.3/66.3 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m622.2/622.2 kB\u001b[0m \u001b[31m52.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.3/363.3 kB\u001b[0m \u001b[31m38.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m24.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.9/34.9 MB\u001b[0m \u001b[31m50.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m82.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m103.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m82.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.1/143.1 kB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Building wheel for ont-bonito (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for mappy (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for ont-remora (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for progressbar33 (setup.py) ... \u001b[?25l\u001b[?25hdone\n"]}],"source":["# install Bonito last version and Pydrive\n","# if the cell is run and a numpy warning pops up, restart kernel and run again the cell\n","# source: https://github.com/nanoporetech/bonito/blob/v0.4.0/notebooks/bonito-train.ipynb\n","\n","!pip install -q ont-bonito\n","!pip install -U -q PyDrive\n","!pip install -q tensorly\n","!pip install -q tensorly-torch\n","!pip install -q fast-ctc-decode\n","\n","import os\n","import sys\n","import time\n","import random\n","from datetime import datetime\n","from itertools import starmap\n","from time import perf_counter\n","from functools import partial\n","import numpy as np\n","import pandas as pd\n","import toml\n","from tqdm import tqdm\n","\n","import torch\n","import torch.nn as nn\n","from torch.nn import Module, ModuleList, Sequential, Conv1d, BatchNorm1d, Dropout, ReLU, SiLU\n","from torch.nn.functional import ctc_loss, log_softmax\n","from torch.optim import AdamW\n","from torch.utils.data import DataLoader\n","from torch.optim.lr_scheduler import CosineAnnealingLR\n","\n","from google.colab import auth\n","from google.colab import drive as gdrive\n","from oauth2client.client import GoogleCredentials\n","from pydrive.auth import GoogleAuth\n","from pydrive.drive import GoogleDrive\n","\n","from bonito.nn import Permute\n","from bonito.util import accuracy, decode_ref, permute, concat\n","from bonito.data import ChunkDataSet\n","from fast_ctc_decode import beam_search, viterbi_search\n","\n","# Tensor decomposition packages\n","import tensorly\n","from tltorch import FactorizedConv"]},{"cell_type":"markdown","metadata":{"id":"_bLgPHnuBxRZ"},"source":["# Models"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AtwebKTr6qdP"},"outputs":[],"source":["class Model(Module):\n","    \"\"\"\n","    Model template for QuartzNet style architectures\n","\n","    https://arxiv.org/pdf/1910.10261.pdf\n","    \"\"\"\n","\n","    def __init__(self, config):\n","        super(Model, self).__init__()\n","        if 'qscore' not in config:\n","            self.qbias = 0.0\n","            self.qscale = 1.0\n","        else:\n","            self.qbias = config['qscore']['bias']\n","            self.qscale = config['qscore']['scale']\n","\n","        self.config = config\n","        self.stride = config['block'][0]['stride'][0]\n","        self.alphabet = config['labels']['labels']\n","        self.features = config['block'][-1]['filters']\n","        self.encoder = Encoder(config)\n","        self.decoder = Decoder(self.features, len(self.alphabet))\n","\n","    def forward(self, x):\n","        encoded = self.encoder(x)\n","        return self.decoder(encoded)\n","\n","    def decode(self, x, beamsize=5, threshold=1e-3, qscores=False, return_path=False):\n","        x = x.exp().cpu().numpy().astype(np.float32)\n","        if beamsize == 1 or qscores:\n","            seq, path  = viterbi_search(x, self.alphabet, qscores, self.qscale, self.qbias)\n","        else:\n","            seq, path = beam_search(x, self.alphabet, beamsize, threshold)\n","        if return_path: return seq, path\n","        return seq\n","\n","\n","class Encoder(Module):\n","    \"\"\"\n","    Builds the model encoder\n","    \"\"\"\n","    def __init__(self, config):\n","        super(Encoder, self).__init__()\n","        self.config = config\n","\n","        self.activations = {\"relu\": ReLU,\"swish\": SiLU}\n","        features = self.config['input']['features']\n","        activation = self.activations[self.config['encoder']['activation']]()\n","        encoder_layers = []\n","\n","        for layer in self.config['block']:\n","            encoder_layers.append(\n","                Block(\n","                    features, layer['filters'], activation,\n","                    repeat=layer['repeat'], kernel_size=layer['kernel'],\n","                    stride=layer['stride'], dilation=layer['dilation'],\n","                    dropout=layer['dropout'], residual=layer['residual'],\n","                    separable=layer['separable'],\n","                )\n","            )\n","\n","            features = layer['filters']\n","\n","        self.encoder = Sequential(*encoder_layers)\n","\n","    def forward(self, x):\n","        return self.encoder(x)\n","\n","\n","class TCSConv1d(Module):\n","    \"\"\"\n","    Time-Channel Separable 1D Convolution\n","    \"\"\"\n","    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=False, separable=False):\n","\n","        super(TCSConv1d, self).__init__()\n","        self.separable = separable\n","\n","        if separable:\n","            # This layer cannot be factorised until \"groups is implemented in tensorly-torch\".\n","            self.depthwise = Conv1d(\n","                in_channels, in_channels, kernel_size=kernel_size, stride=stride,\n","                padding=padding, dilation=dilation, bias=bias, groups=in_channels\n","            )\n","\n","            self.pointwise = Conv1d(\n","                in_channels, out_channels, kernel_size=1, stride=1,\n","                dilation=dilation, bias=bias, padding=0\n","            )\n","\n","        else:\n","            self.conv = Conv1d(\n","                in_channels, out_channels, kernel_size=kernel_size,\n","                stride=stride, padding=padding, dilation=dilation, bias=bias\n","            )\n","\n","    def forward(self, x):\n","        if self.separable:\n","            x = self.depthwise(x)\n","            x = self.pointwise(x)\n","        else:\n","            x = self.conv(x)\n","        return x\n","\n","\n","class Block(Module):\n","    \"\"\"\n","    TCSConv, Batch Normalisation, Activation, Dropout\n","    \"\"\"\n","    def __init__(self, in_channels, out_channels, activation, repeat=5, kernel_size=1, stride=1, dilation=1, dropout=0.0, residual=False, separable=False):\n","\n","        super(Block, self).__init__()\n","\n","        self.use_res = residual\n","        self.conv = ModuleList()\n","\n","        _in_channels = in_channels\n","        padding = self.get_padding(kernel_size[0], stride[0], dilation[0])\n","\n","        # add the first n - 1 convolutions + activation\n","        for _ in range(repeat - 1):\n","            self.conv.extend(\n","                self.get_tcs(\n","                    _in_channels, out_channels, kernel_size=kernel_size,\n","                    stride=stride, dilation=dilation,\n","                    padding=padding, separable=separable\n","                )\n","            )\n","\n","            self.conv.extend(self.get_activation(activation, dropout))\n","            _in_channels = out_channels\n","\n","        # add the last conv and batch norm\n","        self.conv.extend(\n","            self.get_tcs(\n","                _in_channels, out_channels,\n","                kernel_size=kernel_size,\n","                stride=stride, dilation=dilation,\n","                padding=padding, separable=separable\n","            )\n","        )\n","\n","        # add the residual connection\n","        if self.use_res:\n","            self.residual = Sequential(*self.get_tcs(in_channels, out_channels))\n","\n","        # add the activation and dropout\n","        self.activation = Sequential(*self.get_activation(activation, dropout))\n","\n","    def get_activation(self, activation, dropout):\n","        return activation, Dropout(p=dropout)\n","\n","    def get_padding(self, kernel_size, stride, dilation):\n","        if stride > 1 and dilation > 1:\n","            raise ValueError(\"Dilation and stride can not both be greater than 1\")\n","        return (kernel_size // 2) * dilation\n","\n","    def get_tcs(self, in_channels, out_channels, kernel_size=1, stride=1, dilation=1, padding=0, bias=False, separable=False):\n","        return [\n","            TCSConv1d(\n","                in_channels, out_channels, kernel_size,\n","                stride=stride, dilation=dilation, padding=padding,\n","                bias=bias, separable=separable\n","            ),\n","            BatchNorm1d(out_channels, eps=1e-3, momentum=0.1)\n","        ]\n","\n","    def forward(self, x):\n","        _x = x\n","        for layer in self.conv:\n","            _x = layer(_x)\n","        if self.use_res:\n","            _x = _x + self.residual(x)\n","        return self.activation(_x)\n","\n","\n","class Decoder(Module):\n","    \"\"\"\n","    Decoder\n","    \"\"\"\n","    def __init__(self, features, classes):\n","        super(Decoder, self).__init__()\n","        self.layers = Sequential(\n","            Conv1d(features, classes, kernel_size=1, bias=True),\n","            Permute([2, 0, 1])\n","        )\n","\n","    def forward(self, x):\n","        return log_softmax(self.layers(x), dim=2)"]},{"cell_type":"markdown","metadata":{"id":"2s6X35tKJsHH"},"source":["---\n","# DOWNLOAD SAMPLE DATASET"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KA8gyuU--0IN"},"outputs":[],"source":["chunks_link = \"https://drive.google.com/open?id=1aciNfQs53eFRwnMggInY-Uisi-owtmzY\" #@param {type:\"string\"}\n","references_link = \"https://drive.google.com/open?id=1kcs_hZMndUIDX2n8dTxGrAgCvt_TpUcH\" #@param {type:\"string\"}\n","reference_lengths_link = \"https://drive.google.com/open?id=1-r7XymddP_3gKFb-7ohB_t14u7u4SGLm\" #@param {type:\"string\"}\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":408},"executionInfo":{"elapsed":133984,"status":"error","timestamp":1694968124702,"user":{"displayName":"Rodrigo Hernández","userId":"13809504810916014110"},"user_tz":-120},"id":"6znKdewm_lc2","outputId":"6b4f546e-682e-47a8-dbc8-52f103036cd9"},"outputs":[{"ename":"KeyboardInterrupt","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-4-2662f0e2918e>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Authenticate and create PyDrive client.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mauth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauthenticate_user\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mgauth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGoogleAuth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mgauth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcredentials\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGoogleCredentials\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_application_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdrive\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGoogleDrive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgauth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/auth.py\u001b[0m in \u001b[0;36mauthenticate_user\u001b[0;34m(clear_output, project_id)\u001b[0m\n\u001b[1;32m    279\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_check_adc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_CredentialType\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUSER\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0muse_auth_ephem\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 281\u001b[0;31m       _message.blocking_request(\n\u001b[0m\u001b[1;32m    282\u001b[0m           \u001b[0;34m'request_auth'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m           \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'authType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'auth_user_ephemeral'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_next_input_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_NOT_READY\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m       \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.025\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m       \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     if (\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["# Authenticate and create PyDrive client.\n","auth.authenticate_user()\n","gauth = GoogleAuth()\n","gauth.credentials = GoogleCredentials.get_application_default()\n","drive = GoogleDrive(gauth)\n","\n","# helper functions for importing data\n","def download_npy_from_link(fn, link):\n","    _, id = link.split('=')\n","    downloaded = drive.CreateFile({'id':id})\n","    downloaded.GetContentFile(fn)\n","    return np.load(fn)\n","\n","print('Loading chunks.')\n","full_chunks = download_npy_from_link('chunks.npy',\n","                                chunks_link)\n","# Sections of squiggle that correspond with the target reference sequence\n","# Variable length and zero padded (upto 4096 samples).\n","# shape (1000000, 4096)\n","# dtype('float32')\n","\n","print('Loading references.')\n","full_targets = download_npy_from_link('references.npy',\n","                                 references_link)\n","# Integer encoded target sequence {'A': 1, 'C': 2, 'G': 3, 'T': 4}\n","# Variable length and zero padded (default range between 128 and 256).\n","# shape (1000000, 256)\n","# dtype('uint8')\n","\n","print('Loading reference lengths.')\n","full_target_lengths = download_npy_from_link('reference_lengths.npy',\n","                                        reference_lengths_link)\n","# Lengths of target sequences in references.npy\n","# shape (1000000,)\n","# dtype('uint8')\n"]},{"cell_type":"markdown","metadata":{"id":"6B7ybPAvmwQE"},"source":["# DOWNLOAD CONFIG AND LOAD STATE DICT"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":23766,"status":"ok","timestamp":1694968154271,"user":{"displayName":"Rodrigo Hernández","userId":"13809504810916014110"},"user_tz":-120},"id":"2AZcUNkF7UKf","outputId":"4e577f14-8135-4317-b1f6-e32fca520736"},"outputs":[{"name":"stdout","output_type":"stream","text":["Loaded quartznet config.\n"]}],"source":["# Authenticate and create PyDrive client.\n","auth.authenticate_user()\n","gauth = GoogleAuth()\n","gauth.credentials = GoogleCredentials.get_application_default()\n","drive = GoogleDrive(gauth)\n","\n","def download_toml_from_link(fn, link):\n","    _, id = link.split('=')\n","    downloaded = drive.CreateFile({'id':id})\n","    downloaded.GetContentFile(fn)\n","    return toml.load(fn)\n","\n","# Load model configuration\n","\n","# dna_r9.4.1@v1 is heavier\n","quartznet_config_link = \"https://drive.google.com/open?id=1hKKE2Fzp3jdNyZI2h8jnOuwxBOvXWjp6\"\n","quartznet_config = download_toml_from_link(\"dna_r9.4.1@v1.toml\",quartznet_config_link)\n","\n","# dna_r9.4.1@v2 is lighter\n","#quartznet_config_link = \"https://drive.google.com/open?id=1IRDMrnE0WWeiRoioX7NHM5TXezl2jMkN\"\n","#quartznet_config = download_toml_from_link(\"dna_r9.4.1@v2.toml\",quartznet_config_link)\n","\n","# The structure of the model is defined using a config file.\n","# This will make sense to those familar with QuartzNet\n","\n","print('Loaded quartznet config.')\n"]},{"cell_type":"markdown","metadata":{"id":"BEcnlM9rnBVR"},"source":["# TEST SPLIT"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sS98dshWnKvS"},"outputs":[],"source":["epochs = 1\n","random_seed = 25 #@param {type:\"integer\"}\n","batch_size = 16 #@param [2, 4, 8, 16, 28] {type:\"raw\"}\n","num_chunks = 10000 #@param [10, 100, 1000, 10000, 100000] {type:\"raw\"}\n","train_proportion = 0.80 #@param type:\"slider\", min:0.8, max:1000, step:1\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"z-r6N2QxnRd3"},"outputs":[],"source":["# Initialise random libs and setup cudnn\n","random.seed(random_seed)\n","np.random.seed(random_seed)\n","torch.manual_seed(random_seed)\n","torch.backends.cudnn.enabled = True\n","torch.backends.cudnn.deterministic = True\n","torch.backends.cudnn.benchmark = False\n","\n","# we exploit GPU for training\n","device = torch.device(\"cuda\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GzakOaBgnVi1"},"outputs":[],"source":["# subset\n","chunks = full_chunks[:num_chunks]\n","targets = full_targets[:num_chunks]\n","target_lengths = full_target_lengths[:num_chunks]\n","\n","# shuffle\n","shuf = np.random.permutation(chunks.shape[0])\n","chunks = chunks[shuf]\n","targets = targets[shuf]\n","target_lengths = target_lengths[shuf]\n","\n","split = np.floor(chunks.shape[0] * train_proportion).astype(np.int32)"]},{"cell_type":"markdown","metadata":{"id":"s-qRco5SwVKH"},"source":["# Create dict - INITIAL ASSIGNATION LOOP\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UI1FOg8kxwg-"},"outputs":[],"source":["# PARAMETERS:\n","version = \"v1\"\n","FACTORISATION = \"tucker\" # tucker // CP // TT\n","RANK = 1/10\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":40060,"status":"ok","timestamp":1694968360425,"user":{"displayName":"Rodrigo Hernández","userId":"13809504810916014110"},"user_tz":-120},"id":"x-8dHR4w__gS","outputId":"52661099-76fb-4977-ee46-aa3c70daa7bb"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]},{"data":{"text/plain":["<All keys matched successfully>"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["\n","# mount users drive to load data\n","gdrive.mount('/content/drive', force_remount=True)\n","\n","WEIGHT_NAME = f\"weights_uncompressed_{version}\"\n","WEIGHTS_PATH = f\"/content/drive/MyDrive/Quartznet_weights/weights/compressed/\"\n","\n","\n","model = Model(quartznet_config)\n","model.load_state_dict(torch.load(WEIGHTS_PATH + WEIGHT_NAME + \".pt\"))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fr6aKJ_G-cOj"},"outputs":[],"source":["# Initialise convolutional doctionary\n","conv_layers_dict = dict()\n","\n","# Main loop\n","for enc_dec_layer in model._modules.keys():\n","\n","  print(\"[OUTER LAYER]\", enc_dec_layer)\n","\n","  if enc_dec_layer == \"encoder\":\n","    for layer in model.encoder.encoder._modules.keys():\n","      for sublayer in model.encoder.encoder[int(layer)]._modules.keys():\n","\n","        print(\"--------------------------------\", layer, sublayer)\n","\n","        if sublayer == \"conv\":\n","          # add to this condicion: and int(layer) <=3 (<3 works)\n","\n","          for index in  model.encoder.encoder[int(layer)].conv._modules.keys():\n","\n","            if type(model.encoder.encoder[int(layer)].conv[int(index)]) == TCSConv1d:\n","              print(\"[DEBUG ------->>]\", model.encoder.encoder[int(layer)].conv[int(index)])\n","\n","              if \"conv\" in model.encoder.encoder[int(layer)].conv[int(index)]._modules.keys():\n","                print(f\"[DEBUG-PRE-conv] - layer: {layer} - sublayer: {sublayer} - index: {index} - current keys:\", model.encoder.encoder[int(layer)].conv[int(index)]._modules.keys())\n","\n","                # Add to the dict\n","                conv_layers_dict[f\"conv_{layer}{index}\"] = [layer, index, \"conv\"]\n","                print(f\"[DEBUG-DICT] - conv_{layer}{index}\")\n","\n","                # Factorisation\n","                layer_to_factor = model.encoder.encoder[int(layer)].conv[int(index)].conv\n","                rank = layer_to_factor.weight.size(0)//2\n","                model.encoder.encoder[int(layer)].conv[int(index)].conv = FactorizedConv.from_conv(layer_to_factor, rank=RANK, factorization=FACTORISATION, decompose_weights=False)\n","\n","                print(\"[DEBUG-POST]\", type( model.encoder.encoder[int(layer)].conv[int(index)].conv))\n","\n","              if \"pointwise\" in model.encoder.encoder[int(layer)].conv[int(index)]._modules.keys():\n","                print(f\"[DEBUG-PRE-pointwise] - layer: {layer} - sublayer: {sublayer} - index: {index} - current keys:\", model.encoder.encoder[int(layer)].conv[int(index)]._modules.keys())\n","\n","                # Add to the dict\n","                conv_layers_dict[f\"pointwise_{layer}{index}\"] = [layer, index, \"pointwise\"]\n","                print(f\"[DEBUG-DICT] - pointwise_{layer}{index}\")\n","\n","                # Factorisation\n","                layer_to_factor = model.encoder.encoder[int(layer)].conv[int(index)].pointwise\n","                rank = layer_to_factor.weight.size(0)//2\n","                model.encoder.encoder[int(layer)].conv[int(index)].pointwise = FactorizedConv.from_conv(layer_to_factor, rank=RANK, factorization=FACTORISATION, decompose_weights=False)\n","\n","                print(\"[DEBUG]\", type( model.encoder.encoder[int(layer)].conv[int(index)].pointwise))\n","\n","              if \"depthwise\" in model.encoder.encoder[int(layer)].conv[int(index)]._modules.keys():\n","                print(f\"[DEBUG-PRE-depthwise] - layer: {layer} - sublayer: {sublayer} - index: {index} - current keys:\", model.encoder.encoder[int(layer)].conv[int(index)]._modules.keys())\n","\n","                # Add to the dict\n","                conv_layers_dict[f\"depthwise_{layer}{index}\"] = [layer, index, \"depthwise\"]\n","                print(f\"[DEBUG-DICT] - depthwise_{layer}{index}\")\n","\n","                # Factorisation not implemented due to \"groups\" parameter missing in tensorly-torch implementation of \"from_conv()\"\n","                \"\"\"layer_to_factor = model.encoder.encoder[int(layer)].conv[int(index)].depthwise\n","                rank = layer_to_factor.weight.size(0)//2\n","                model.encoder.encoder[int(layer)].conv[int(index)].depthwise = FactorizedConv.from_conv(layer_to_factor, rank=RANK, factorization=FACTORISATION, decompose_weights=False)\"\"\"\n","\n","                print(\"[DEBUG]\", type( model.encoder.encoder[int(layer)].conv[int(index)].depthwise))\n","\n","        elif sublayer == \"residual\":\n","          print(\"[DEBUG ------->>]\", model.encoder.encoder[int(layer)].residual)\n","          \"\"\"for index in  model.encoder.encoder[int(layer)].residual._modules.keys():\n","\n","            if type(model.encoder.encoder[int(layer)].residual[int(index)]) == TCSConv1d:\n","              layer_to_factor = model.encoder.encoder[int(layer)].residual[int(index)].conv\n","              model.encoder.encoder[int(layer)].residual[int(index)].conv = FactorizedConv.from_conv(layer_to_factor, rank=RANK, factorization=FACTORISATION, decompose_weights=False)\n","              print(\"[DEBUG]\", type(model.encoder.encoder[int(layer)].residual[int(index)].conv))\"\"\"\n","\n","  elif enc_dec_layer == \"decoder\":\n","     # Only one layer, hardcoded\n","        \"\"\"print(\"[DEBUG ------->>]\", model.decoder.layers[0])\n","        layer_to_factor = model.decoder.layers[0]\n","        model.decoder.layers[0] = FactorizedConv.from_conv(layer_to_factor, rank=RANK, factorization=FACTORISATION, decompose_weights=False)\n","        print(\"[DEBUG]\", type(model.decoder.layers[0]))\n","        \"\"\"\n","        pass"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"m2BnLjlecJtV"},"outputs":[],"source":["# visualise model architecture\n","model.eval()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2798,"status":"ok","timestamp":1694369015574,"user":{"displayName":"Rodrigo Hernández","userId":"13809504810916014110"},"user_tz":-120},"id":"Y52i1oDCu3PH","outputId":"1cd098cf-1d3f-438d-d761-80acf5bf8b40"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["# mount users drive to save data\n","\n","gdrive.mount('/content/drive', force_remount=True)\n","compressed_weights_savepath = '/content/drive/My Drive/Quartznet_weights/weights/compressed/' #@param {type:\"string\"}\n","\n","# prevent overwriting of data\n","workdir = os.path.join(compressed_weights_savepath, f\"weights_compressed_{version}_{FACTORISATION}_{RANK}.pt\")\n","\n","# Data to be written\n","torch.save(model.state_dict(), workdir)\n"]},{"cell_type":"markdown","metadata":{"id":"nU7l9Lwoua5k"},"source":["# TEST MODEL"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UVV_a-U9nbqd"},"outputs":[],"source":["# Test function obtained from v3.0 (https://github.com/nanoporetech/bonito/blob/v0.3.0/bonito/training.py)\n","\n","def ctc_label_smoothing_loss(log_probs, targets, lengths, weights):\n","    T, N, C = log_probs.shape\n","    log_probs_lengths = torch.full(size=(N, ), fill_value=T, dtype=torch.int64)\n","    loss = ctc_loss(log_probs.to(torch.float32), targets, log_probs_lengths, lengths, reduction='mean')\n","    label_smoothing_loss = -((log_probs * weights.to(log_probs.device)).mean())\n","    return {'loss': loss + label_smoothing_loss, 'ctc_loss': loss, 'label_smooth_loss': label_smoothing_loss}\n","\n","\n","def test(model, device, test_loader, min_coverage=0.5, criterion=None):\n","\n","    if criterion is None:\n","        C = len(model.alphabet)\n","        weights = torch.cat([torch.tensor([0.4]), (0.1 / (C - 1)) * torch.ones(C - 1)]).to(device)\n","        criterion = partial(ctc_label_smoothing_loss, weights=weights)\n","\n","    seqs = []\n","    model.eval()\n","    test_loss = 0\n","    accuracy_with_cov = lambda ref, seq: accuracy(ref, seq, min_coverage=min_coverage)\n","\n","    with torch.no_grad():\n","        for batch_idx, (data, target, lengths) in enumerate(test_loader, start=1):\n","            log_probs = model(data.to(device))\n","            loss = criterion(log_probs, target.to(device), lengths.to(device))\n","            test_loss += loss['ctc_loss'] if isinstance(loss, dict) else loss\n","            seqs.extend([model.decode(p) for p in permute(log_probs, 'TNC', 'NTC')])\n","\n","    refs = [\n","        decode_ref(target, model.alphabet) for target in test_loader.dataset.targets\n","    ]\n","    accuracies = [\n","        accuracy_with_cov(ref, seq) if len(seq) else 0. for ref, seq in zip(refs, seqs)\n","    ]\n","\n","    mean = np.mean(accuracies)\n","    median = np.median(accuracies)\n","    return test_loss.item() / batch_idx, mean, median"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":200},"executionInfo":{"elapsed":49876,"status":"ok","timestamp":1694370687901,"user":{"displayName":"Rodrigo Hernández","userId":"13809504810916014110"},"user_tz":-120},"id":"-Rz_mps-mmMI","outputId":"f0cc2383-7b00-4529-fd63-2749e4e17fc2"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]},{"data":{"text/html":["\n","  <div id=\"df-54254b9e-c0f9-48ad-a57e-9ea05b9cd2c2\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>time</th>\n","      <th>epoch</th>\n","      <th>validation_loss</th>\n","      <th>validation_mean</th>\n","      <th>validation_median</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>2023-09-10 18:31:26.971587</td>\n","      <td>1</td>\n","      <td>7.390095</td>\n","      <td>0.517643</td>\n","      <td>0.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-54254b9e-c0f9-48ad-a57e-9ea05b9cd2c2')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-54254b9e-c0f9-48ad-a57e-9ea05b9cd2c2 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-54254b9e-c0f9-48ad-a57e-9ea05b9cd2c2');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","    </div>\n","  </div>\n"],"text/plain":["                        time  epoch  validation_loss  validation_mean  \\\n","0 2023-09-10 18:31:26.971587      1         7.390095         0.517643   \n","\n","   validation_median  \n","0                0.0  "]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["<ipython-input-65-f694d721858c>:52: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  training_results = training_results.append(epoch_result)\n"]},{"data":{"text/html":["\n","  <div id=\"df-68b38b38-8e11-43ff-baf4-3c8fa94f3cdc\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>time</th>\n","      <th>epoch</th>\n","      <th>validation_loss</th>\n","      <th>validation_mean</th>\n","      <th>validation_median</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>2023-09-10 18:31:26.971587</td>\n","      <td>1</td>\n","      <td>7.390095</td>\n","      <td>0.517643</td>\n","      <td>0.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-68b38b38-8e11-43ff-baf4-3c8fa94f3cdc')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-68b38b38-8e11-43ff-baf4-3c8fa94f3cdc button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-68b38b38-8e11-43ff-baf4-3c8fa94f3cdc');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","    </div>\n","  </div>\n"],"text/plain":["                        time  epoch  validation_loss  validation_mean  \\\n","0 2023-09-10 18:31:26.971587      1         7.390095         0.517643   \n","\n","   validation_median  \n","0                0.0  "]},"metadata":{},"output_type":"display_data"}],"source":["# savepath\n","workdir = '/content/drive/My Drive/Quartznet_weights/weights/compressed/' #@param {type:\"string\"}\n","\n","# mount users drive to save data\n","gdrive.mount('/content/drive', force_remount=True)\n","\n","# data generators\n","test_dataset = ChunkDataSet(chunks[split:], targets[split:], target_lengths[split:])\n","\n","# data loader\n","test_loader = DataLoader(test_dataset, batch_size=batch_size,\n","                         num_workers=2, pin_memory=True)\n","# Cuda\n","model.to(device)\n","\n","# 'Connectionist Temporal Classification' (CTC) loss fuction\n","# https://distill.pub/2017/ctc/\n","criterion = nn.CTCLoss(reduction='mean')\n","\n","# report loss every\n","interval = 500 / num_chunks\n","log_interval = np.floor(len(test_dataset) / batch_size * interval)\n","\n","exp_config = os.path.join(workdir, \"experimental.log\")\n","with open(exp_config, 'a') as c:\n","    c.write('Num training chunks: {}'.format(num_chunks) + '\\n')\n","    c.write('random seed: {}'.format(random_seed) + '\\n')\n","    c.write('epochs: {}'.format(epochs) + '\\n')\n","    c.write('batch_size: {}'.format(batch_size) + '\\n')\n","    c.write('train proportion: {}'.format(train_proportion) + '\\n')\n","\n","# DataFrame to store training logging information\n","training_results = pd.DataFrame()\n","\n","for epoch in range(1, epochs + 1):\n","    # v3.0\n","    test_loss, mean, median = test(model, device, test_loader)\n","\n","    # collate training and validation metrics\n","    epoch_result = pd.DataFrame(\n","        {'time':[datetime.today()],\n","         'epoch':[epoch],\n","         'validation_loss':[test_loss],\n","         'validation_mean':[mean],\n","         'validation_median':[median]})\n","\n","    # update log file\n","    log_path = os.path.join(workdir, WEIGHTS_PATH + f\"{RANK}_{FACTORISATION}_{version}.log\")\n","    epoch_result.to_csv(log_path, mode='a', sep='\\t', index=False)\n","\n","    display(epoch_result)\n","    training_results = training_results.append(epoch_result)\n","\n","display(training_results)"]},{"cell_type":"markdown","metadata":{"id":"OkQBXodcvA4J"},"source":["# Results: parameters"]},{"cell_type":"markdown","metadata":{"id":"6-SRinXw4CIF"},"source":["Import example from:\n","https://github.com/JeanKossaifi/tensorly-notebooks/blob/master/05_pytorch_backend/cnn_acceleration_tensorly_and_pytorch.ipynb"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1694368225439,"user":{"displayName":"Rodrigo Hernández","userId":"13809504810916014110"},"user_tz":-120},"id":"WkEuE3CnsTE5","outputId":"42c6c0ab-c21b-4ede-f4ba-2d85f08861b6"},"outputs":[{"data":{"text/plain":["1245262"]},"execution_count":91,"metadata":{},"output_type":"execute_result"}],"source":["# ---------------0.13--------------------\n","\n","# Tucker (rank=1/8)\n","# v1\n","# Original: 6678533\n","# Compressed: 1414436\n","\n","# v2\n","# Original: 6649613\n","# Compressed: 1256840\n","\n","# -------------------------------------\n","\n","# CP (rank=1/8)\n","# v1\n","# Original: 6678533\n","# Compressed: 1393154\n","\n","# v2\n","# Original: 6649613\n","# Compressed: 1238177\n","\n","# -------------------------------------\n","\n","# TT (rank=1/8)\n","# v1\n","# Original: 6678533\n","# Compressed: 1393357\n","\n","# v2\n","# Original: 6649613\n","# Compressed: 1245262\n","\n","# -------------------------------------\n","\n","\n","np.sum([np.prod(p.size()) for p in model.parameters()])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1694368362557,"user":{"displayName":"Rodrigo Hernández","userId":"13809504810916014110"},"user_tz":-120},"id":"Y4hWtCO0sUKm","outputId":"3fdcb52b-e93b-4e63-f2be-091e88c93a8e"},"outputs":[{"data":{"text/plain":["1496878"]},"execution_count":103,"metadata":{},"output_type":"execute_result"}],"source":["\n","# ---------------0.18--------------------\n","\n","# Tucker (rank=1/6)\n","# v1\n","# Original: 6678533\n","# Compressed: 1686356\n","\n","# v2\n","# Original: 6649613\n","# Compressed: 1542487\n","# -------------------------------------\n","\n","# CP (rank=1/6)\n","# v1\n","# Original: 6678533\n","# Compressed: 1648459\n","\n","# v2\n","# Original: 6649613\n","# Compressed: 1503985\n","\n","# -------------------------------------\n","\n","# TT (rank=1/6)\n","# v1\n","# Original: 6678533\n","# Compressed: 1646083\n","\n","# v2\n","# Original: 6649613\n","# Compressed: 1496878\n","\n","# -------------------------------------\n","\n","\n","np.sum([np.prod(p.size()) for p in model.parameters()])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":213,"status":"ok","timestamp":1694368557227,"user":{"displayName":"Rodrigo Hernández","userId":"13809504810916014110"},"user_tz":-120},"id":"gZfJ-HuCRg3z","outputId":"aec4ca22-2567-41c7-8527-492461c85965"},"outputs":[{"data":{"text/plain":["2532887"]},"execution_count":118,"metadata":{},"output_type":"execute_result"}],"source":["\n","# ---------------0.35--------------------\n","\n","# Tucker (rank=1/3)\n","# v1\n","# Original: 6678533\n","# Compressed: 2777034\n","\n","# v2\n","# Original: 6649613\n","# Compressed: 2657400\n","# -------------------------------------\n","\n","# CP (rank=1/3)\n","# v1\n","# Original: 6678533\n","# Compressed: 2651531\n","\n","# v2\n","# Original: 6649613\n","# Compressed: 2532753\n","\n","# -------------------------------------\n","\n","# TT (rank=1/3)\n","# v1\n","# Original: 6678533\n","# Compressed: 2649484\n","\n","# v2\n","# Original: 6649613\n","# Compressed: 2532887\n","\n","# -------------------------------------\n","\n","\n","np.sum([np.prod(p.size()) for p in model.parameters()])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":253,"status":"ok","timestamp":1694368687271,"user":{"displayName":"Rodrigo Hernández","userId":"13809504810916014110"},"user_tz":-120},"id":"CBNBXAQaSwbC","outputId":"c317fa80-7df9-46bf-a1ad-16cab374fd81"},"outputs":[{"data":{"text/plain":["3555824"]},"execution_count":131,"metadata":{},"output_type":"execute_result"}],"source":["\n","# ---------------0.53--------------------\n","\n","# Tucker (rank=1/2)\n","# v1\n","# Original: 6678533\n","# Compressed: 3907062\n","\n","# v2\n","# Original: 6649613\n","# Compressed: 3829391\n","# -------------------------------------\n","\n","# CP (rank=1/2)\n","# v1\n","# Original: 6678533\n","# Compressed: 3663306\n","\n","# v2\n","# Original: 6649613\n","# Compressed: 3566653\n","\n","# -------------------------------------\n","\n","# TT (rank=1/2)\n","# v1\n","# Original: 6678533\n","# Compressed: 3659028\n","\n","# v2\n","# Original: 6649613\n","# Compressed: 3555824\n","\n","# -------------------------------------\n","\n","\n","np.sum([np.prod(p.size()) for p in model.parameters()])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":313,"status":"ok","timestamp":1694368887992,"user":{"displayName":"Rodrigo Hernández","userId":"13809504810916014110"},"user_tz":-120},"id":"ahUlRJ_jTjEV","outputId":"fe6800f5-dca4-474b-9985-2ac292177b38"},"outputs":[{"data":{"text/plain":["4801893"]},"execution_count":143,"metadata":{},"output_type":"execute_result"}],"source":["\n","# ---------------0.7--------------------\n","\n","# Tucker (rank=0.7)\n","# v1\n","# Original: 6678533\n","# Compressed: 5296541\n","\n","# v2\n","# Original: 6649613\n","# Compressed: 5222229\n","# -------------------------------------\n","\n","# CP (rank=0.7)\n","# v1\n","# Original: 6678533\n","# Compressed: 4866478\n","\n","# v2\n","# Original: 6649613\n","# Compressed: 4802220\n","\n","# -------------------------------------\n","\n","# TT (rank=0.7)\n","# v1\n","# Original: 6678533\n","# Compressed: 4876031\n","\n","# v2\n","# Original: 6649613\n","# Compressed: 4801893\n","\n","# -------------------------------------\n","\n","\n","np.sum([np.prod(p.size()) for p in model.parameters()])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":307,"status":"ok","timestamp":1694369018643,"user":{"displayName":"Rodrigo Hernández","userId":"13809504810916014110"},"user_tz":-120},"id":"UBH8ayj_UqiK","outputId":"468c781c-1fe0-4975-b69c-f3b702f99ac8"},"outputs":[{"data":{"text/plain":["5416497"]},"execution_count":156,"metadata":{},"output_type":"execute_result"}],"source":["\n","# ---------------0.85--------------------\n","\n","# Tucker (rank=0.8)\n","# v1\n","# Original: 6678533\n","# Compressed: 5973758\n","\n","# v2\n","# Original: 6649613\n","# Compressed: 5922946\n","# -------------------------------------\n","\n","# CP (rank=0.8)\n","# v1\n","# Original: 6678533\n","# Compressed: 5480530\n","\n","# v2\n","# Original: 6649613\n","# Compressed: 5419782\n","\n","# -------------------------------------\n","\n","# TT (rank=0.8)\n","# v1\n","# Original: 6678533\n","# Compressed: 5468291\n","\n","# v2\n","# Original: 6649613\n","# Compressed: 5416497\n","\n","# -------------------------------------\n","\n","\n","np.sum([np.prod(p.size()) for p in model.parameters()])"]},{"cell_type":"markdown","metadata":{"id":"LMWj6DBzdX7F"},"source":["# FINE TUNING MODEL"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QEUBU95bXZEf"},"outputs":[],"source":["\n","model_savepath = '/content/drive/My Drive/Quartznet_weights/' #@param {type:\"string\"}\n","learning_rate = 0.001 #@param {type:\"number\"}\n","random_seed = 25 #@param {type:\"integer\"}\n","epochs = 20 #@param {type:\"slider\", min:1, max:1000, step:1}\n","batch_size = 16 #@param [2, 4, 8, 16, 28] {type:\"raw\"}\n","num_chunks = 10000 #@param [10, 100, 1000, 10000, 100000] {type:\"raw\"}\n","train_proportion = 0.80 #@param type:\"slider\", min:0.8, max:1000, step:1\n","dropout = 0.0 #@param {type:\"slider\", min:0.0, max:0.8}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8wqExXxsYDV9"},"outputs":[],"source":["def train(model, device, train_loader, optimizer, use_amp=False, criterion=None, lr_scheduler=None, loss_log=None):\n","\n","    if criterion is None:\n","        C = len(model.alphabet)\n","        weights = torch.cat([torch.tensor([0.4]), (0.1 / (C - 1)) * torch.ones(C - 1)]).to(device)\n","        criterion = partial(ctc_label_smoothing_loss, weights=weights)\n","\n","    chunks = 0\n","    model.train()\n","    t0 = perf_counter()\n","\n","    progress_bar = tqdm(\n","        total=len(train_loader), desc='[0/{}]'.format(len(train_loader.dataset)),\n","        ascii=True, leave=True, ncols=100, bar_format='{l_bar}{bar}| [{elapsed}{postfix}]'\n","    )\n","    smoothed_loss = {}\n","\n","    with progress_bar:\n","\n","        for data, targets, lengths in train_loader:\n","\n","            optimizer.zero_grad()\n","\n","            chunks += data.shape[0]\n","\n","            # DEBUG MODE\n","            #display(\"[DEBUG]----------------\", model(data.to(device)))\n","\n","            log_probs = model(data.to(device))\n","            losses = criterion(log_probs, targets.to(device), lengths.to(device))\n","\n","            if not isinstance(losses, dict):\n","                losses = {'loss': losses}\n","\n","            if use_amp:\n","                pass\n","            else:\n","                losses['loss'].backward()\n","\n","            optimizer.step()\n","\n","            if lr_scheduler is not None: lr_scheduler.step()\n","\n","            if not smoothed_loss:\n","                smoothed_loss = {k: v.item() for k,v in losses.items()}\n","            smoothed_loss = {k: 0.01 * v.item() + 0.99 * smoothed_loss[k] for k,v in losses.items()}\n","\n","            progress_bar.set_postfix(loss='%.4f' % smoothed_loss['loss'])\n","            progress_bar.set_description(\"[{}/{}]\".format(chunks, len(train_loader.dataset)))\n","            progress_bar.update()\n","\n","            if loss_log is not None:\n","                loss_log.append({'chunks': chunks, 'time': perf_counter() - t0, **smoothed_loss})\n","\n","    return smoothed_loss['loss'], perf_counter() - t0\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":583},"executionInfo":{"elapsed":225043,"status":"error","timestamp":1694447184960,"user":{"displayName":"Rodrigo Hernández","userId":"13809504810916014110"},"user_tz":-120},"id":"-2lpYXoUYEl5","outputId":"302b7cef-669d-4ad9-aa36-7a856365c62c"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]},{"name":"stderr","output_type":"stream","text":["[1264/8000]:  16%|#########4                                                  | [01:32, loss=1.6007]"]}],"source":["#@title Set experiment name\n","experiment_name = f'bonito_training_nodecodernoresidual_{FACTORISATION}_{RANK}_{version}' #@param {type:\"string\"}\n","\n","# mount users drive to save data\n","gdrive.mount('/content/drive', force_remount=True)\n","\n","# prevent overwriting of data\n","workdir = os.path.join(model_savepath, experiment_name)\n","if os.path.isdir(workdir):\n","    raise IOError('{} already exists. Select an alternative model_savepath.'.format(workdir))\n","os.makedirs(workdir)\n","\n","# data generators\n","train_dataset = ChunkDataSet(chunks[:split], targets[:split], target_lengths[:split])\n","test_dataset = ChunkDataSet(chunks[split:], targets[split:], target_lengths[split:])\n","\n","\n","# data loaders\n","train_loader = DataLoader(train_dataset, batch_size=batch_size,\n","                          shuffle=True, num_workers=2, pin_memory=True)\n","test_loader = DataLoader(test_dataset, batch_size=batch_size,\n","                         num_workers=2, pin_memory=True)\n","\n","# Cuda\n","model.to(device)\n","\n","# load bonito model\n","model.train()\n","\n","# 'Connectionist Temporal Classification' (CTC) loss fuction\n","# https://distill.pub/2017/ctc/\n","criterion = nn.CTCLoss(reduction='mean')\n","\n","# set optimizer and learning rate scheduler\n","optimizer = AdamW(model.parameters(), amsgrad=True, lr=learning_rate)\n","schedular = CosineAnnealingLR(optimizer, epochs * len(train_loader))\n","\n","# report loss every\n","interval = 500 / num_chunks\n","log_interval = np.floor(len(train_dataset) / batch_size * interval)\n","\n","exp_config = os.path.join(workdir, \"experimental.log\")\n","with open(exp_config, 'a') as c:\n","    c.write('Num training chunks: {}'.format(num_chunks) + '\\n')\n","    c.write('learning rate: {}'.format(learning_rate) + '\\n')\n","    c.write('random seed: {}'.format(random_seed) + '\\n')\n","    c.write('epochs: {}'.format(epochs) + '\\n')\n","    c.write('batch_size: {}'.format(batch_size) + '\\n')\n","    c.write('train proportion: {}'.format(train_proportion) + '\\n')\n","    c.write('dropout: {}'.format(dropout) + '\\n')\n","\n","# DataFrame to store training logging information\n","training_results = pd.DataFrame()\n","\n","for epoch in range(1, epochs + 1):\n","    # v3.0\n","    train_loss, duration = train(model, device, train_loader, optimizer)\n","\n","    test_loss, mean, median = test(model, device, test_loader)\n","\n","    # collate training and validation metrics\n","    epoch_result = pd.DataFrame(\n","        {'time':[datetime.today()],\n","         'duration':[int(duration)],\n","         'epoch':[epoch],\n","         'train_loss':[train_loss],\n","         'validation_loss':[test_loss],\n","         'validation_mean':[mean],\n","         'validation_median':[median]})\n","\n","    # save model weights\n","    weights_path = os.path.join(workdir, \"weights_%s.pt\" % epoch)\n","    torch.save(model.state_dict(), weights_path)\n","\n","    # update log file\n","    log_path = os.path.join(workdir, \"training.log\")\n","    epoch_result.to_csv(log_path, mode='a', sep='\\t', index=False)\n","\n","    display(epoch_result)\n","    training_results = training_results.append(epoch_result)\n","\n","    schedular.step()\n","\n","display(training_results)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":256,"status":"ok","timestamp":1694447233090,"user":{"displayName":"Rodrigo Hernández","userId":"13809504810916014110"},"user_tz":-120},"id":"Tgta5_3b7Ab8","outputId":"b0803aa7-ddd1-427d-d2bf-f413e1ca54b4"},"outputs":[{"data":{"text/plain":["6678533"]},"execution_count":35,"metadata":{},"output_type":"execute_result"}],"source":["np.sum([np.prod(p.size()) for p in model.parameters()])\n","\n","# 1971831 -> 0.1 tucker v1\n","# 6678533 -> original"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IGnd0wSdYfmp"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["_bLgPHnuBxRZ","2s6X35tKJsHH","BEcnlM9rnBVR"],"machine_shape":"hm","toc_visible":true,"provenance":[],"mount_file_id":"15m7EzI-Q_6ohD87Z4t4jSIHwQinhL9k4","authorship_tag":"ABX9TyPbpQqxgxJjjSJo2TM6oxYs"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}