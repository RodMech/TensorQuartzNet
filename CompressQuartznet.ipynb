{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","toc_visible":true,"gpuType":"T4","collapsed_sections":["S9hRTj3XwgZi"],"mount_file_id":"15m7EzI-Q_6ohD87Z4t4jSIHwQinhL9k4","authorship_tag":"ABX9TyM1YnmbMKiJbbBg+WJOzWbr"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"WCRMTi9y3y_h"},"outputs":[],"source":["# install Bonito last version and Pydrive\n","# if the cell is run and a numpy warning pops up, restart kernel and run again the cell\n","# source: https://github.com/nanoporetech/bonito/blob/v0.4.0/notebooks/bonito-train.ipynb\n","\n","!pip install -q ont-bonito\n","!pip install -U -q PyDrive\n","!pip install -q tensorly\n","!pip install -q tensorly-torch\n","!pip install -q fast-ctc-decode\n","\n","import os\n","import sys\n","import time\n","import random\n","from datetime import datetime\n","from itertools import starmap\n","from time import perf_counter\n","from functools import partial\n","import numpy as np\n","import pandas as pd\n","import toml\n","from tqdm import tqdm\n","\n","import torch\n","import torch.nn as nn\n","from torch.nn import Module, ModuleList, Sequential, Conv1d, BatchNorm1d, Dropout, ReLU, SiLU\n","from torch.nn.functional import ctc_loss, log_softmax\n","from torch.optim import AdamW\n","from torch.utils.data import DataLoader\n","from torch.optim.lr_scheduler import CosineAnnealingLR\n","\n","from google.colab import auth\n","from google.colab import drive as gdrive\n","from oauth2client.client import GoogleCredentials\n","from pydrive.auth import GoogleAuth\n","from pydrive.drive import GoogleDrive\n","\n","from bonito.nn import Permute\n","from fast_ctc_decode import beam_search, viterbi_search\n","\n","# Tensor decomposition packages\n","import tensorly\n","from tltorch import FactorizedConv"]},{"cell_type":"markdown","source":["# Models"],"metadata":{"id":"_bLgPHnuBxRZ"}},{"cell_type":"code","source":["class Model(Module):\n","    \"\"\"\n","    Model template for QuartzNet style architectures\n","\n","    https://arxiv.org/pdf/1910.10261.pdf\n","    \"\"\"\n","\n","    def __init__(self, config):\n","        super(Model, self).__init__()\n","        if 'qscore' not in config:\n","            self.qbias = 0.0\n","            self.qscale = 1.0\n","        else:\n","            self.qbias = config['qscore']['bias']\n","            self.qscale = config['qscore']['scale']\n","\n","        self.config = config\n","        self.stride = config['block'][0]['stride'][0]\n","        self.alphabet = config['labels']['labels']\n","        self.features = config['block'][-1]['filters']\n","        self.encoder = Encoder(config)\n","        self.decoder = Decoder(self.features, len(self.alphabet))\n","\n","    def forward(self, x):\n","        encoded = self.encoder(x)\n","        return self.decoder(encoded)\n","\n","    def decode(self, x, beamsize=5, threshold=1e-3, qscores=False, return_path=False):\n","        x = x.exp().cpu().numpy().astype(np.float32)\n","        if beamsize == 1 or qscores:\n","            seq, path  = viterbi_search(x, self.alphabet, qscores, self.qscale, self.qbias)\n","        else:\n","            seq, path = beam_search(x, self.alphabet, beamsize, threshold)\n","        if return_path: return seq, path\n","        return seq\n","\n","\n","class Encoder(Module):\n","    \"\"\"\n","    Builds the model encoder\n","    \"\"\"\n","    def __init__(self, config):\n","        super(Encoder, self).__init__()\n","        self.config = config\n","\n","        self.activations = {\"relu\": ReLU,\"swish\": SiLU}\n","        features = self.config['input']['features']\n","        activation = self.activations[self.config['encoder']['activation']]()\n","        encoder_layers = []\n","\n","        for layer in self.config['block']:\n","            encoder_layers.append(\n","                Block(\n","                    features, layer['filters'], activation,\n","                    repeat=layer['repeat'], kernel_size=layer['kernel'],\n","                    stride=layer['stride'], dilation=layer['dilation'],\n","                    dropout=layer['dropout'], residual=layer['residual'],\n","                    separable=layer['separable'],\n","                )\n","            )\n","\n","            features = layer['filters']\n","\n","        self.encoder = Sequential(*encoder_layers)\n","\n","    def forward(self, x):\n","        return self.encoder(x)\n","\n","\n","class TCSConv1d(Module):\n","    \"\"\"\n","    Time-Channel Separable 1D Convolution\n","    \"\"\"\n","    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=False, separable=False):\n","\n","        super(TCSConv1d, self).__init__()\n","        self.separable = separable\n","\n","        if separable:\n","            # This layer cannot be factorised until \"groups is implemented in tensorly-torch\".\n","            self.depthwise = Conv1d(\n","                in_channels, in_channels, kernel_size=kernel_size, stride=stride,\n","                padding=padding, dilation=dilation, bias=bias, groups=in_channels\n","            )\n","\n","            self.pointwise = Conv1d(\n","                in_channels, out_channels, kernel_size=1, stride=1,\n","                dilation=dilation, bias=bias, padding=0\n","            )\n","\n","        else:\n","            self.conv = Conv1d(\n","                in_channels, out_channels, kernel_size=kernel_size,\n","                stride=stride, padding=padding, dilation=dilation, bias=bias\n","            )\n","\n","    def forward(self, x):\n","        if self.separable:\n","            x = self.depthwise(x)\n","            x = self.pointwise(x)\n","        else:\n","            x = self.conv(x)\n","        return x\n","\n","\n","class Block(Module):\n","    \"\"\"\n","    TCSConv, Batch Normalisation, Activation, Dropout\n","    \"\"\"\n","    def __init__(self, in_channels, out_channels, activation, repeat=5, kernel_size=1, stride=1, dilation=1, dropout=0.0, residual=False, separable=False):\n","\n","        super(Block, self).__init__()\n","\n","        self.use_res = residual\n","        self.conv = ModuleList()\n","\n","        _in_channels = in_channels\n","        padding = self.get_padding(kernel_size[0], stride[0], dilation[0])\n","\n","        # add the first n - 1 convolutions + activation\n","        for _ in range(repeat - 1):\n","            self.conv.extend(\n","                self.get_tcs(\n","                    _in_channels, out_channels, kernel_size=kernel_size,\n","                    stride=stride, dilation=dilation,\n","                    padding=padding, separable=separable\n","                )\n","            )\n","\n","            self.conv.extend(self.get_activation(activation, dropout))\n","            _in_channels = out_channels\n","\n","        # add the last conv and batch norm\n","        self.conv.extend(\n","            self.get_tcs(\n","                _in_channels, out_channels,\n","                kernel_size=kernel_size,\n","                stride=stride, dilation=dilation,\n","                padding=padding, separable=separable\n","            )\n","        )\n","\n","        # add the residual connection\n","        if self.use_res:\n","            self.residual = Sequential(*self.get_tcs(in_channels, out_channels))\n","\n","        # add the activation and dropout\n","        self.activation = Sequential(*self.get_activation(activation, dropout))\n","\n","    def get_activation(self, activation, dropout):\n","        return activation, Dropout(p=dropout)\n","\n","    def get_padding(self, kernel_size, stride, dilation):\n","        if stride > 1 and dilation > 1:\n","            raise ValueError(\"Dilation and stride can not both be greater than 1\")\n","        return (kernel_size // 2) * dilation\n","\n","    def get_tcs(self, in_channels, out_channels, kernel_size=1, stride=1, dilation=1, padding=0, bias=False, separable=False):\n","        return [\n","            TCSConv1d(\n","                in_channels, out_channels, kernel_size,\n","                stride=stride, dilation=dilation, padding=padding,\n","                bias=bias, separable=separable\n","            ),\n","            BatchNorm1d(out_channels, eps=1e-3, momentum=0.1)\n","        ]\n","\n","    def forward(self, x):\n","        _x = x\n","        for layer in self.conv:\n","            _x = layer(_x)\n","        if self.use_res:\n","            _x = _x + self.residual(x)\n","        return self.activation(_x)\n","\n","\n","class Decoder(Module):\n","    \"\"\"\n","    Decoder\n","    \"\"\"\n","    def __init__(self, features, classes):\n","        super(Decoder, self).__init__()\n","        self.layers = Sequential(\n","            Conv1d(features, classes, kernel_size=1, bias=True),\n","            Permute([2, 0, 1])\n","        )\n","\n","    def forward(self, x):\n","        return log_softmax(self.layers(x), dim=2)"],"metadata":{"id":"AtwebKTr6qdP"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Load config"],"metadata":{"id":"IWrZNGTAB3nG"}},{"cell_type":"code","source":["# Authenticate and create PyDrive client.\n","auth.authenticate_user()\n","gauth = GoogleAuth()\n","gauth.credentials = GoogleCredentials.get_application_default()\n","drive = GoogleDrive(gauth)\n","\n","def download_toml_from_link(fn, link):\n","    _, id = link.split('=')\n","    downloaded = drive.CreateFile({'id':id})\n","    downloaded.GetContentFile(fn)\n","    return toml.load(fn)\n","\n","# Load model configuration\n","\n","# dna_r9.4.1@v1 is heavier\n","#quartznet_config_link = \"https://drive.google.com/open?id=1hKKE2Fzp3jdNyZI2h8jnOuwxBOvXWjp6\"\n","#quartznet_config = download_toml_from_link(\"dna_r9.4.1@v1.toml\",quartznet_config_link)\n","\n","# dna_r9.4.1@v2 is lighter\n","quartznet_config_link = \"https://drive.google.com/open?id=1IRDMrnE0WWeiRoioX7NHM5TXezl2jMkN\"\n","quartznet_config = download_toml_from_link(\"dna_r9.4.1@v2.toml\",quartznet_config_link)\n","\n","# The structure of the model is defined using a config file.\n","# This will make sense to those familar with QuartzNet\n","\n","print('Loaded quartznet config.')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2AZcUNkF7UKf","executionInfo":{"status":"ok","timestamp":1694368123579,"user_tz":-120,"elapsed":1261,"user":{"displayName":"Rodrigo Hernández","userId":"13809504810916014110"}},"outputId":"dd3212ca-8650-4035-9f67-0aa56800e401"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Loaded quartznet config.\n"]}]},{"cell_type":"markdown","source":["# Load state dict"],"metadata":{"id":"POkdn05rB8LM"}},{"cell_type":"code","source":["\n","# mount users drive to load data\n","gdrive.mount('/content/drive', force_remount=True)\n","\n","WEIGHTS_PATH = \"/content/drive/MyDrive/Quartznet_weights/weights/last/weights_v2.pt\"\n","\n","\n","model = Model(quartznet_config)\n","\n","model.load_state_dict(torch.load(WEIGHTS_PATH))\n"],"metadata":{"id":"x-8dHR4w__gS","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1694369004618,"user_tz":-120,"elapsed":3060,"user":{"displayName":"Rodrigo Hernández","userId":"13809504810916014110"}},"outputId":"90f094d5-bb73-4213-8e98-e22da0d990e2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]},{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{},"execution_count":153}]},{"cell_type":"markdown","source":["# Create dict - INITIAL ASSIGNATION LOOP\n"],"metadata":{"id":"s-qRco5SwVKH"}},{"cell_type":"code","source":["# PARAMETERS:\n","FACTORISATION = \"TT\" # tucker // CP // TT\n","RANK = 0.8\n","\n","# Initialise convolutional doctionary\n","conv_layers_dict = dict()\n","\n","# Main loop\n","for enc_dec_layer in model._modules.keys():\n","\n","  print(\"[OUTER LAYER]\", enc_dec_layer)\n","\n","  if enc_dec_layer == \"encoder\":\n","    for layer in model.encoder.encoder._modules.keys():\n","      for sublayer in model.encoder.encoder[int(layer)]._modules.keys():\n","\n","        print(\"--------------------------------\", layer, sublayer)\n","\n","        if sublayer == \"conv\":\n","          # add to this condicion: and int(layer) <=3 (<3 works)\n","\n","          for index in  model.encoder.encoder[int(layer)].conv._modules.keys():\n","\n","            if type(model.encoder.encoder[int(layer)].conv[int(index)]) == TCSConv1d:\n","              print(\"[DEBUG ------->>]\", model.encoder.encoder[int(layer)].conv[int(index)])\n","\n","              if \"conv\" in model.encoder.encoder[int(layer)].conv[int(index)]._modules.keys():\n","                print(f\"[DEBUG-PRE-conv] - layer: {layer} - sublayer: {sublayer} - index: {index} - current keys:\", model.encoder.encoder[int(layer)].conv[int(index)]._modules.keys())\n","\n","                # Add to the dict\n","                conv_layers_dict[f\"conv_{layer}{index}\"] = [layer, index, \"conv\"]\n","                print(f\"[DEBUG-DICT] - conv_{layer}{index}\")\n","\n","                # Factorisation\n","                layer_to_factor = model.encoder.encoder[int(layer)].conv[int(index)].conv\n","                rank = layer_to_factor.weight.size(0)//2\n","                model.encoder.encoder[int(layer)].conv[int(index)].conv = FactorizedConv.from_conv(layer_to_factor, rank=RANK, factorization=FACTORISATION, decompose_weights=False)\n","\n","                print(\"[DEBUG-POST]\", type( model.encoder.encoder[int(layer)].conv[int(index)].conv))\n","\n","              if \"pointwise\" in model.encoder.encoder[int(layer)].conv[int(index)]._modules.keys():\n","                print(f\"[DEBUG-PRE-pointwise] - layer: {layer} - sublayer: {sublayer} - index: {index} - current keys:\", model.encoder.encoder[int(layer)].conv[int(index)]._modules.keys())\n","\n","                # Add to the dict\n","                conv_layers_dict[f\"pointwise_{layer}{index}\"] = [layer, index, \"pointwise\"]\n","                print(f\"[DEBUG-DICT] - pointwise_{layer}{index}\")\n","\n","                # Factorisation\n","                layer_to_factor = model.encoder.encoder[int(layer)].conv[int(index)].pointwise\n","                rank = layer_to_factor.weight.size(0)//2\n","                model.encoder.encoder[int(layer)].conv[int(index)].pointwise = FactorizedConv.from_conv(layer_to_factor, rank=RANK, factorization=FACTORISATION, decompose_weights=False)\n","\n","                print(\"[DEBUG]\", type( model.encoder.encoder[int(layer)].conv[int(index)].pointwise))\n","\n","              if \"depthwise\" in model.encoder.encoder[int(layer)].conv[int(index)]._modules.keys():\n","                print(f\"[DEBUG-PRE-depthwise] - layer: {layer} - sublayer: {sublayer} - index: {index} - current keys:\", model.encoder.encoder[int(layer)].conv[int(index)]._modules.keys())\n","\n","                # Add to the dict\n","                conv_layers_dict[f\"depthwise_{layer}{index}\"] = [layer, index, \"depthwise\"]\n","                print(f\"[DEBUG-DICT] - depthwise_{layer}{index}\")\n","\n","                # Factorisation needs to be removed as Tensorly-Torch has not implemented groups=in_channels, and the weights are not properly factorised\n","                \"\"\"layer_to_factor = model.encoder.encoder[int(layer)].conv[int(index)].depthwise\n","                rank = layer_to_factor.weight.size(0)//2\n","                model.encoder.encoder[int(layer)].conv[int(index)].depthwise = FactorizedConv.from_conv(layer_to_factor, rank=RANK, factorization=FACTORISATION, decompose_weights=False)\"\"\"\n","\n","                print(\"[DEBUG]\", type( model.encoder.encoder[int(layer)].conv[int(index)].depthwise))\n","\n","        elif sublayer == \"residual\":\n","          print(\"[DEBUG ------->>]\", model.encoder.encoder[int(layer)].residual)\n","          for index in  model.encoder.encoder[int(layer)].residual._modules.keys():\n","\n","            if type(model.encoder.encoder[int(layer)].residual[int(index)]) == TCSConv1d:\n","              layer_to_factor = model.encoder.encoder[int(layer)].residual[int(index)].conv\n","              model.encoder.encoder[int(layer)].residual[int(index)].conv = FactorizedConv.from_conv(layer_to_factor, rank=RANK, factorization=FACTORISATION, decompose_weights=False)\n","              print(\"[DEBUG]\", type(model.encoder.encoder[int(layer)].residual[int(index)].conv))\n","\n","  elif enc_dec_layer == \"decoder\":\n","     # Only one layer, hardcoded\n","        print(\"[DEBUG ------->>]\", model.decoder.layers[0])\n","        layer_to_factor = model.decoder.layers[0]\n","        model.decoder.layers[0] = FactorizedConv.from_conv(layer_to_factor, rank=RANK, factorization=FACTORISATION, decompose_weights=False)\n","        print(\"[DEBUG]\", type(model.decoder.layers[0]))\n"],"metadata":{"id":"fr6aKJ_G-cOj"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# DUMP / LOAD JSON"],"metadata":{"id":"S9hRTj3XwgZi"}},{"cell_type":"code","source":["import json\n","# mount users drive to save data\n","gdrive.mount('/content/drive', force_remount=True)\n","dict_savepath = '/content/drive/My Drive/Quartznet_weights/weights/json/' #@param {type:\"string\"}\n","\n","# prevent overwriting of data\n","workdir = os.path.join(dict_savepath)\n","\n","# Data to be written\n","with open(workdir+\"layers.json\", \"w\") as outfile:\n","    json.dump(conv_layers_dict, outfile)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yBQIG_RTqb_V","executionInfo":{"status":"ok","timestamp":1694275890027,"user_tz":-120,"elapsed":3120,"user":{"displayName":"Rodrigo Hernández","userId":"13809504810916014110"}},"outputId":"da79d5cd-17c3-4096-de7c-af60f7a27100"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["import json\n","# mount users drive to save data\n","gdrive.mount('/content/drive', force_remount=True)\n","dict_savepath = '/content/drive/My Drive/Quartznet_weights/weights/json/' #@param {type:\"string\"}\n","\n","# prevent overwriting of data\n","workdir = os.path.join(dict_savepath)\n","\n","# Data to be written\n","with open(workdir+\"layers.json\", \"r\") as data:\n","    conv_dict = json.load(data)\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KcZZoK0Zsm8b","executionInfo":{"status":"ok","timestamp":1694278899692,"user_tz":-120,"elapsed":4291,"user":{"displayName":"Rodrigo Hernández","userId":"13809504810916014110"}},"outputId":"ba6ee3f1-852b-46b7-b69b-4184f96f9b53"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","source":["# SAVE COMPRESSED MODEL"],"metadata":{"id":"nU7l9Lwoua5k"}},{"cell_type":"code","source":["# visualise model architecture\n","model.eval()"],"metadata":{"id":"-Rz_mps-mmMI","colab":{"base_uri":"https://localhost:8080/","height":200},"executionInfo":{"status":"error","timestamp":1695395310214,"user_tz":-120,"elapsed":9,"user":{"displayName":"Rodrigo Hernández","userId":"13809504810916014110"}},"outputId":"4e279dec-001c-4dd4-ce57-b4baf26407f1"},"execution_count":1,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-a637edd61686>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# visualise model architecture\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"]}]},{"cell_type":"code","source":["# mount users drive to save data\n","\n","gdrive.mount('/content/drive', force_remount=True)\n","compressed_weights_savepath = '/content/drive/My Drive/Quartznet_weights/weights/compressed/' #@param {type:\"string\"}\n","\n","# prevent overwriting of data\n","workdir = os.path.join(compressed_weights_savepath, \"weights_compressed_TT_v2.pt\")\n","\n","# Data to be written\n","torch.save(model.state_dict(), workdir)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Y52i1oDCu3PH","executionInfo":{"status":"ok","timestamp":1694369015574,"user_tz":-120,"elapsed":2798,"user":{"displayName":"Rodrigo Hernández","userId":"13809504810916014110"}},"outputId":"1cd098cf-1d3f-438d-d761-80acf5bf8b40"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","source":["# Results: parameters"],"metadata":{"id":"OkQBXodcvA4J"}},{"cell_type":"markdown","source":["Import example from:\n","https://github.com/JeanKossaifi/tensorly-notebooks/blob/master/05_pytorch_backend/cnn_acceleration_tensorly_and_pytorch.ipynb"],"metadata":{"id":"6-SRinXw4CIF"}},{"cell_type":"code","source":["# ---------------0.13--------------------\n","\n","# Tucker (rank=1/8)\n","# v1\n","# Original: 6678533\n","# Compressed: 1414436\n","\n","# v2\n","# Original: 6649613\n","# Compressed: 1256840\n","\n","# -------------------------------------\n","\n","# CP (rank=1/8)\n","# v1\n","# Original: 6678533\n","# Compressed: 1393154\n","\n","# v2\n","# Original: 6649613\n","# Compressed: 1238177\n","\n","# -------------------------------------\n","\n","# TT (rank=1/8)\n","# v1\n","# Original: 6678533\n","# Compressed: 1393357\n","\n","# v2\n","# Original: 6649613\n","# Compressed: 1245262\n","\n","# -------------------------------------\n","\n","\n","np.sum([np.prod(p.size()) for p in model.parameters()])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WkEuE3CnsTE5","executionInfo":{"status":"ok","timestamp":1694368225439,"user_tz":-120,"elapsed":3,"user":{"displayName":"Rodrigo Hernández","userId":"13809504810916014110"}},"outputId":"42c6c0ab-c21b-4ede-f4ba-2d85f08861b6"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1245262"]},"metadata":{},"execution_count":91}]},{"cell_type":"code","source":["\n","# ---------------0.18--------------------\n","\n","# Tucker (rank=1/6)\n","# v1\n","# Original: 6678533\n","# Compressed: 1686356\n","\n","# v2\n","# Original: 6649613\n","# Compressed: 1542487\n","# -------------------------------------\n","\n","# CP (rank=1/6)\n","# v1\n","# Original: 6678533\n","# Compressed: 1648459\n","\n","# v2\n","# Original: 6649613\n","# Compressed: 1503985\n","\n","# -------------------------------------\n","\n","# TT (rank=1/6)\n","# v1\n","# Original: 6678533\n","# Compressed: 1646083\n","\n","# v2\n","# Original: 6649613\n","# Compressed: 1496878\n","\n","# -------------------------------------\n","\n","\n","np.sum([np.prod(p.size()) for p in model.parameters()])"],"metadata":{"id":"Y4hWtCO0sUKm","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1694368362557,"user_tz":-120,"elapsed":5,"user":{"displayName":"Rodrigo Hernández","userId":"13809504810916014110"}},"outputId":"3fdcb52b-e93b-4e63-f2be-091e88c93a8e"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1496878"]},"metadata":{},"execution_count":103}]},{"cell_type":"code","source":["\n","# ---------------0.35--------------------\n","\n","# Tucker (rank=1/3)\n","# v1\n","# Original: 6678533\n","# Compressed: 2777034\n","\n","# v2\n","# Original: 6649613\n","# Compressed: 2657400\n","# -------------------------------------\n","\n","# CP (rank=1/3)\n","# v1\n","# Original: 6678533\n","# Compressed: 2651531\n","\n","# v2\n","# Original: 6649613\n","# Compressed: 2532753\n","\n","# -------------------------------------\n","\n","# TT (rank=1/3)\n","# v1\n","# Original: 6678533\n","# Compressed: 2649484\n","\n","# v2\n","# Original: 6649613\n","# Compressed: 2532887\n","\n","# -------------------------------------\n","\n","\n","np.sum([np.prod(p.size()) for p in model.parameters()])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gZfJ-HuCRg3z","executionInfo":{"status":"ok","timestamp":1694368557227,"user_tz":-120,"elapsed":213,"user":{"displayName":"Rodrigo Hernández","userId":"13809504810916014110"}},"outputId":"aec4ca22-2567-41c7-8527-492461c85965"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["2532887"]},"metadata":{},"execution_count":118}]},{"cell_type":"code","source":["\n","# ---------------0.53--------------------\n","\n","# Tucker (rank=1/2)\n","# v1\n","# Original: 6678533\n","# Compressed: 3907062\n","\n","# v2\n","# Original: 6649613\n","# Compressed: 3829391\n","# -------------------------------------\n","\n","# CP (rank=1/2)\n","# v1\n","# Original: 6678533\n","# Compressed: 3663306\n","\n","# v2\n","# Original: 6649613\n","# Compressed: 3566653\n","\n","# -------------------------------------\n","\n","# TT (rank=1/2)\n","# v1\n","# Original: 6678533\n","# Compressed: 3659028\n","\n","# v2\n","# Original: 6649613\n","# Compressed: 3555824\n","\n","# -------------------------------------\n","\n","\n","np.sum([np.prod(p.size()) for p in model.parameters()])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CBNBXAQaSwbC","executionInfo":{"status":"ok","timestamp":1694368687271,"user_tz":-120,"elapsed":253,"user":{"displayName":"Rodrigo Hernández","userId":"13809504810916014110"}},"outputId":"c317fa80-7df9-46bf-a1ad-16cab374fd81"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["3555824"]},"metadata":{},"execution_count":131}]},{"cell_type":"code","source":["\n","# ---------------0.7--------------------\n","\n","# Tucker (rank=0.7)\n","# v1\n","# Original: 6678533\n","# Compressed: 5296541\n","\n","# v2\n","# Original: 6649613\n","# Compressed: 5222229\n","# -------------------------------------\n","\n","# CP (rank=0.7)\n","# v1\n","# Original: 6678533\n","# Compressed: 4866478\n","\n","# v2\n","# Original: 6649613\n","# Compressed: 4802220\n","\n","# -------------------------------------\n","\n","# TT (rank=0.7)\n","# v1\n","# Original: 6678533\n","# Compressed: 4876031\n","\n","# v2\n","# Original: 6649613\n","# Compressed: 4801893\n","\n","# -------------------------------------\n","\n","\n","np.sum([np.prod(p.size()) for p in model.parameters()])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ahUlRJ_jTjEV","executionInfo":{"status":"ok","timestamp":1694368887992,"user_tz":-120,"elapsed":313,"user":{"displayName":"Rodrigo Hernández","userId":"13809504810916014110"}},"outputId":"fe6800f5-dca4-474b-9985-2ac292177b38"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["4801893"]},"metadata":{},"execution_count":143}]},{"cell_type":"code","source":["\n","# ---------------0.85--------------------\n","\n","# Tucker (rank=0.8)\n","# v1\n","# Original: 6678533\n","# Compressed: 5973758\n","\n","# v2\n","# Original: 6649613\n","# Compressed: 5922946\n","# -------------------------------------\n","\n","# CP (rank=0.8)\n","# v1\n","# Original: 6678533\n","# Compressed: 5480530\n","\n","# v2\n","# Original: 6649613\n","# Compressed: 5419782\n","\n","# -------------------------------------\n","\n","# TT (rank=0.8)\n","# v1\n","# Original: 6678533\n","# Compressed: 5468291\n","\n","# v2\n","# Original: 6649613\n","# Compressed: 5416497\n","\n","# -------------------------------------\n","\n","\n","np.sum([np.prod(p.size()) for p in model.parameters()])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UBH8ayj_UqiK","executionInfo":{"status":"ok","timestamp":1694369018643,"user_tz":-120,"elapsed":307,"user":{"displayName":"Rodrigo Hernández","userId":"13809504810916014110"}},"outputId":"468c781c-1fe0-4975-b69c-f3b702f99ac8"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["5416497"]},"metadata":{},"execution_count":156}]},{"cell_type":"code","source":[],"metadata":{"id":"RjWF8M7lO9VK"},"execution_count":null,"outputs":[]}]}